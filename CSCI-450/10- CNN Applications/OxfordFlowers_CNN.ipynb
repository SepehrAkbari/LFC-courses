{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82fde532-0c6a-4745-b195-8e87b949c8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import os\n",
    "from skimage import io, color, transform, exposure\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "555deee2-d68c-4cb9-91e5-5ad8baca4d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = scipy.io.loadmat('../../data/OxfordFlowers/imagelabels.mat')\n",
    "labels = temp['labels']\n",
    "labels = labels.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae9f5a5d-4d6e-4e95-9867-444c69b47614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8189,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2229071d-cd5b-4a2b-8725-a4534d4094c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp = scipy.io.loadmat('../../data/OxfordFlowers/setid.mat')\n",
    "# trnid = temp['trnid'].flatten()\n",
    "# valid = temp['valid'].flatten()\n",
    "# tstid = temp['tstid'].flatten()\n",
    "\n",
    "# print(trnid.shape, valid.shape, tstid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85a63a48-fcb5-4c5e-a5ca-2ae600013d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imagefiles</th>\n",
       "      <th>segmfiles</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../../data/OxfordFlowers/jpg/image_07088.jpg</td>\n",
       "      <td>../../data/OxfordFlowers/segmim/image_07088.jpg</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../../data/OxfordFlowers/jpg/image_06396.jpg</td>\n",
       "      <td>../../data/OxfordFlowers/segmim/image_06396.jpg</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../../data/OxfordFlowers/jpg/image_05847.jpg</td>\n",
       "      <td>../../data/OxfordFlowers/segmim/image_05847.jpg</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../../data/OxfordFlowers/jpg/image_04581.jpg</td>\n",
       "      <td>../../data/OxfordFlowers/segmim/image_04581.jpg</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../../data/OxfordFlowers/jpg/image_03588.jpg</td>\n",
       "      <td>../../data/OxfordFlowers/segmim/image_03588.jpg</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     imagefiles  \\\n",
       "0  ../../data/OxfordFlowers/jpg/image_07088.jpg   \n",
       "1  ../../data/OxfordFlowers/jpg/image_06396.jpg   \n",
       "2  ../../data/OxfordFlowers/jpg/image_05847.jpg   \n",
       "3  ../../data/OxfordFlowers/jpg/image_04581.jpg   \n",
       "4  ../../data/OxfordFlowers/jpg/image_03588.jpg   \n",
       "\n",
       "                                         segmfiles labels  \n",
       "0  ../../data/OxfordFlowers/segmim/image_07088.jpg     77  \n",
       "1  ../../data/OxfordFlowers/segmim/image_06396.jpg     77  \n",
       "2  ../../data/OxfordFlowers/segmim/image_05847.jpg     77  \n",
       "3  ../../data/OxfordFlowers/segmim/image_04581.jpg     77  \n",
       "4  ../../data/OxfordFlowers/segmim/image_03588.jpg     77  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagepath = '../../data/OxfordFlowers/jpg'\n",
    "segpath = '../../data/OxfordFlowers/segmim'\n",
    "\n",
    "filenames = os.listdir(imagepath)\n",
    "imagefiles = []\n",
    "segmfiles = []\n",
    "for i in range(len(filenames)):\n",
    "    imagefiles.append(imagepath + '/' + filenames[i])\n",
    "    segmfiles.append(segpath + '/' + filenames[i])\n",
    "\n",
    "data = {'imagefiles':imagefiles, 'segmfiles':segmfiles, 'labels':labels}\n",
    "alldata = pd.DataFrame(data)\n",
    "alldata['labels'] = alldata.labels.astype(str)\n",
    "alldata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8f2f74d-6236-4163-960d-6c4f44e4f3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19cc2bad-3105-469e-822b-3be1ab68d586",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = 500\n",
    "BATCH_SIZE = 16\n",
    "NUMCLASSES = len(alldata.labels.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d606db39-954c-40f3-aefb-ad0792cffc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(img):\n",
    "    if len(img.shape)==2:\n",
    "        img = np.stack([img, img, img], axis = 2)\n",
    "\n",
    "    img = img - np.min(img)\n",
    "    img = img / np.max(img)\n",
    "    \n",
    "    img = img - np.mean(img)\n",
    "    img = img / np.std(img)   \n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7149f92-3292-4a9a-8feb-cc805fa027f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6551, 3) (1638, 3)\n"
     ]
    }
   ],
   "source": [
    "traindata, testdata = train_test_split(alldata, test_size=0.2,\n",
    "                                                                stratify=alldata.labels)\n",
    "print(traindata.shape,testdata.shape)\n",
    "traindata = traindata.sample(frac=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "311dffc5-e1c2-4ca4-8a0f-a895bbd0046b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "                                featurewise_center=False,\n",
    "                                samplewise_center=False,\n",
    "                                featurewise_std_normalization=False,\n",
    "                                samplewise_std_normalization=False,\n",
    "                                zca_epsilon=1e-06,\n",
    "                                rotation_range=5,\n",
    "                                width_shift_range=0.05,\n",
    "                                height_shift_range=0.05,\n",
    "                                brightness_range=None,\n",
    "                                shear_range=0.5,\n",
    "                                zoom_range=0.05,\n",
    "                                channel_shift_range=0.0,\n",
    "                                fill_mode=\"nearest\",\n",
    "                                cval=0.0,\n",
    "                                horizontal_flip=True,\n",
    "                                vertical_flip=False,\n",
    "                                rescale=None,\n",
    "                                preprocessing_function=preprocess,\n",
    "                                data_format=None,\n",
    "                                validation_split=0.2,\n",
    "                                dtype=None,\n",
    "                            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92f2bd55-5196-428a-bff0-2aa8c52ec628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5241 validated image filenames belonging to 102 classes.\n",
      "Found 1310 validated image filenames belonging to 102 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_dataframe(\n",
    "                                            dataframe=traindata,\n",
    "                                            directory='',\n",
    "                                            x_col=\"imagefiles\",\n",
    "                                            y_col=\"labels\",\n",
    "                                            #weight_col=None,\n",
    "                                            target_size=(INPUT_SIZE, INPUT_SIZE),\n",
    "                                            color_mode=\"rgb\",\n",
    "                                            classes=None,\n",
    "                                            class_mode=\"categorical\",\n",
    "                                            batch_size=BATCH_SIZE,\n",
    "                                            shuffle=True,\n",
    "                                            seed=None,\n",
    "                                            save_to_dir=None,\n",
    "                                            save_prefix=\"\",\n",
    "                                            save_format=\"png\",\n",
    "                                            subset='training',\n",
    "                                            interpolation=\"nearest\",\n",
    "                                            #validate_filenames=True\n",
    "                                        )\n",
    "\n",
    "validation_set = train_datagen.flow_from_dataframe( dataframe=traindata,\n",
    "                                            directory='',\n",
    "                                            x_col=\"imagefiles\",\n",
    "                                            y_col=\"labels\",\n",
    "                                            #weight_col=None,\n",
    "                                            target_size=(INPUT_SIZE, INPUT_SIZE),\n",
    "                                            color_mode=\"rgb\",\n",
    "                                            classes=None,\n",
    "                                            class_mode=\"categorical\",\n",
    "                                            batch_size=BATCH_SIZE,\n",
    "                                            shuffle=True,\n",
    "                                            seed=None,\n",
    "                                            save_to_dir=None,\n",
    "                                            save_prefix=\"\",\n",
    "                                            save_format=\"png\",\n",
    "                                            subset='validation',\n",
    "                                            interpolation=\"nearest\",\n",
    "                                            #validate_filenames=True\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "585e138c-cb94-4649-a81f-59ff54a0efe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 167, 167, 64)      9472      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 56, 56, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 56, 56, 64)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 28, 28, 64)        102464    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 14, 14, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 14, 14, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 7, 7, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 7, 7, 128)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6272)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               802944    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 102)               13158     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                6592      \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 102)               6630      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,015,116\n",
      "Trainable params: 1,015,116\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(InputLayer(input_shape=[INPUT_SIZE,INPUT_SIZE,3])) #keras will internally add batch dimension\n",
    "\n",
    "model.add(Conv2D(filters=64,kernel_size=7,strides=3,padding='same', activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=3,padding='same'))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(filters=64,kernel_size=5,strides=2,padding='same', activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=2,padding='same'))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Conv2D(filters=128,kernel_size=3,strides=1,padding='same', activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=2,padding='same'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(NUMCLASSES,activation='softmax'))\n",
    "\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(NUMCLASSES,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a101bac-009d-45f8-907b-b6aec707a494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 14:05:30.762146: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/328 [==========>...................] - ETA: 1:01 - loss: 4.6005 - accuracy: 0.0204    "
     ]
    }
   ],
   "source": [
    "#Training\n",
    "\n",
    "epochs = 10\n",
    "history = model.fit(training_set,\n",
    "               epochs=epochs,\n",
    "               validation_data=validation_set)\n",
    "\n",
    "model.save_weights(\"flowers-model-10.weights.h5\")\n",
    "print(\"Saved model to disk after\",epochs,\"epochs.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2e824d-0ed0-4634-8e2a-19b8f14b89a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
