---
title: "Math 250 Midterm 2"
author: "Sepehr Akbari"
date: "11/15/2024"
format: html
embed-resources: true
---

## Setup

```{r}
#| message: False
#| warning: False
#| filename: "packages & libraries"

library(tidyverse)
library(gt)
library(readxl)
```

```{r}
#| message: False
#| warning: False
#| filename: "loading data"

amy_winehouse <- read_csv("amy_winehouse.csv")
block_stacking <- read_excel("block_stacking.xlsx")
```

## Problem 1

To (re)create the summary table, we first group the data by album name and calculate the number of tracks, the average danceability, and the total duration in seconds for each album. We can then add two additional columns to represent the total duration in minutes and seconds. Finally, we arrange the table in descending order based on the number of tracks.

```{r}
#| message: False
#| warning: False
#| filename: "album(s) summary"

amy_winehouse_albums <- amy_winehouse %>%
  group_by(album_name) %>% # grouping by albums
  summarize(
    tracks = n(), # number of tracks per album
    mean_danceability = mean(danceability), # average danceability per album
    total_seconds_rounded = round(sum(duration_ms) / 1000) # total duration in seconds per album
  ) %>%
  mutate(
    whole_min = floor(total_seconds_rounded / 60), # whole minutes from total seconds
    seconds = total_seconds_rounded %% 60 # remaining seconds from total seconds
  ) %>%
  arrange(desc(tracks)) # arranging by number of tracks in descending order
```

We use `gt()` to display the summary table, using `cols_label()` to rename the columns to match the prompt's requirements.

```{r}
#| message: False
#| warning: False
#| filename: "displaying data"

amy_winehouse_albums %>%
  gt() %>% # displaying the summary table
  cols_label( # renaming the columns
    album_name = "Album name",
    tracks = "Tracks",
    mean_danceability = "Avg danceability",
    total_seconds_rounded = "Tot sec (rounded)",
    whole_min = "Whole min",
    seconds = "Sec"
  )
```

## Problem 2

We use the `filter()` function to show only the specified albums from the original dataset. We then use the `select()` function to include only the columns starting with "track", and other specified columns. All saved into a new data frame called `amy_sm`.

```{r}
#| message: False
#| warning: False
#| filename: "filtering data"

amy_sm <- amy_winehouse %>% 
  filter( # filtering the data to only contain the specified albums
    album_name %in% c("At The BBC", 
                      "Frank (Deluxe Edition)", 
                      "Back To Black (Deluxe Edition)")
  ) %>% 
  select( # including only the specified columns
    starts_with("track"), # getting all columns starting with "track"
    album_name,
    explicit,
    energy,
    danceability
  )
```

`amy_sm` is then displayed using `glimpse()` to provide a concise overview of the data frame's structure.

```{r}
#| message: False
#| warning: False
#| filename: "displaying data"

glimpse(amy_sm) # glimpse the new data frame (to see the structure)
```

## Problem 3

We group the data by album name and explicit content, calculating the average energy and the total number of tracks for **each combination**. We then ungroup the data and arrange it by album name to match the order of the prompt's requirements.

```{r}
#| message: False
#| warning: False
#| filename: "albums summary"

amy_sm_summary <- amy_sm %>% 
  group_by(album_name, explicit) %>% # grouping by album name and explicit to get combinations
  summarize(
    avg_energy = mean(energy), # average energy per combination
    tracks = n() # number of tracks per combination
  ) %>% 
  ungroup() %>% # ungrouping the data so we can arrange it
  arrange(album_name) # arranging by album name (alphabetical order)
```

We can then use `gt()` to display the table.

```{r}
#| message: False
#| warning: False
#| filename: "displaying data"

gt(amy_sm_summary) # displaying the summary table
```

## Problem 4

We are asking if the data provide evidence that danceability is related to the album, implying an interest in testing whether album choice affects danceability. The null hypothesis assumes no relationship, meaning album choice does not influence the average danceability of Amy Winehouse’s songs.

***Null hypothesis:*** *The average danceability of Amy Winehouse’s songs is the same across albums.*

$H_0: \mu_{At The BBC} = \mu_{Frank (Deluxe Edition)} = \mu_{Back To Black (Deluxe Edition)}$

The alternative hypothesis suggests a relationship between album and danceability, where at least one album has a different average danceability. This aligns with our question's aim of finding evidence that album choice is related to danceability.

***Alternative hypothesis:*** *The average danceability of Amy Winehouse’s songs differs across albums.*

$H_1: \text{At least one } \mu_i \text{ differs from the others}$

Let’s visualize the distribution of danceability across albums in the sample data to explore how danceability may vary between different albums. I'll use boxplots, as they are ideal for displaying the distribution of danceability across albums, highlighting the median, spread, and any potential outliers within each album category. Additionally, adding `geom_jitter` helps visualize individual song data points, providing a clearer view of variability and overlap between albums.

```{r}
#| message: False
#| warning: False
#| fig-alt: "Boxplot showing the distribution of danceability across a sample of Amy Winehouse albums."
#| filename: "visualizing data"

# alt-text included for accessibility
ggplot( # plotting
  amy_sm, 
  aes(x = album_name,
      y = danceability, 
      fill = album_name) # just for color distinction and aesthetics
  ) +
  geom_boxplot(show.legend = FALSE) + # boxplot, and no need for legend
  # adding jitter for individual points to get a better sense of the data
  geom_jitter(aes(color = album_name),
              width = 0.2, 
              alpha = 0.6, 
              show.legend = FALSE
              # these parameters are for aesthetics
  ) + 
  # improving clarity with labels and title
  labs(x = "Album",
       y = "Danceability",
       title = "Danceability of Amy Winehouse Songs by Album"
  ) +
  theme_minimal() + # minimal theme for more clarity
  scale_fill_brewer(palette = "Dark2") +
  scale_color_brewer(palette = "Dark2") # accessible color palette
```

The plot reveals variation in the distribution of danceability scores across Amy Winehouse’s albums. We can observe that “Frank (Deluxe Edition)” has a higher median danceability compared to the other albums, with a wider range, while “At The BBC” shows a lower and more consistent spread. “Back To Black (Deluxe Edition)” falls in between, with moderate spread and median values. Let's look at a summary of mean danceability across albums to make a more informed comparison.

```{r}
#| message: False
#| warning: False
#| filename: "danceability means"

amy_sm_danceability <- amy_sm %>%
  group_by(album_name) %>% # grouping by album name
  # calculating the mean danceability for each album and rounding results
  summarise(mean_danceability = round(mean(danceability),2)) %>%
  ungroup() 
```

```{r}
#| message: False
#| warning: False
#| filename: "displaying data"

amy_sm_danceability %>%
  gt() %>% # displaying the data
  cols_label( # renaming the columns for clarity
    album_name = "Album",
    mean_danceability = "Mean Danceability"
  )
```

The spread and median differences highly suggest possible variations in danceability across albums. Therefore, we need to do a further statistical analysis to determine if these observed differences are significant or not.

ANOVA is appropriate for this analysis (assuming conditions such as normality, Homogeneity of variance, etc. is met) because it allows us to compare the mean danceability across multiple albums to determine if there are statistically significant differences. By comparing a quantitative variable (danceability) across multiple levels of a categorical variable (album), ANOVA is well-suited to test whether the mean danceability varies between albums.

```{r}
#| message: False
#| warning: False
#| filename: "running ANOVA"

model <- aov(danceability ~ album_name, data = amy_sm) # ANOVE test
summary(model) # displaying the ANOVA results
```

The ANOVA test yields a p-value of $9.53 \times 10^{-5}$, which is well below the typical significance level of 0.05. This low p-value provides strong statistical evidence to **reject the null hypothesis**, indicating that the average danceability of Amy Winehouse’s songs significantly differs across albums. Thus, we conclude that **album choice is related to the danceability of her songs, suggesting that certain albums may have distinct levels of danceability.**

Since our ANOVA analysis revealed significant differences in danceability between albums, we proceed with a Tukey HSD post-hoc test. This test will help pinpoint which specific pairs of albums exhibit these differences, providing further insight into how danceability varies across Amy Winehouse’s discography.

```{r}
TukeyHSD(model) # Tukey's HSD test for post-hoc comparisons
```

The Tukey HSD test confirms that only “Frank (Deluxe Edition)” and “At The BBC” exhibit a significant difference in mean danceability, with “Frank (Deluxe Edition)” songs being more danceable on average. This suggests that while “Frank (Deluxe Edition)” stands out in terms of danceability, “Back To Black (Deluxe Edition)” and “At The BBC” do not differ significantly in this characteristic, indicating that album-specific features in danceability are not uniformly distinct across all albums.

## Problem 5

We are asking if the data provide evidence that the numbers of children in each neighborhood are equal, meaning that any differences in observed counts would be due to random variation in sampling rather than an actual disparity.

***Null hypothesis:*** *The proportion of children in each of the 3 neighborhoods are all 1/3.*

$H_0: \mu_{1} = \mu_{2} = \mu_{3}$


The alternative hypothesis represents the possibility that the numbers of children differ between neighborhoods, implying that at least one neighborhood has a different number of children. This would suggest that the observed distribution does not match an equal distribution across neighborhoods.

***Alternative hypothesis:*** *The proportion of children in each of the 3 neighborhoods are not all 1/3.*

$H_1: \text{At least one } \mu_i \text{ differs from the others}$

Let’s visualize the distribution of children across neighborhoods to explore potential differences in counts. I’ll use a bar chart, which is ideal for displaying categorical counts and allows us to easily compare the numbers of children across neighborhoods.

```{r}
#| message: False
#| warning: False
#| fig-alt: "Bar plot showing the distribution of children across neighborhoods."
#| filename: "visualizing data"

# alt-text included for accessibility
ggplot( # plotting
  block_stacking, 
  aes(x = factor(Neighborhood),
      fill = factor(Neighborhood)) # just for color distinction and aesthetics 
  ) +
  geom_bar(show.legend = FALSE) + # bar plot, and no need for legend
  # improving clarity with labels and title
  labs(x = "Neighborhood",
       y = "Number of Children",
       title = "Distribution of Children Across Neighborhoods"
  ) +
  theme_minimal() + # minimal theme for more clarity
  scale_fill_brewer(palette = "Dark2") # accessible color palette
```

The plot shows that the number of children varies across neighborhoods, with Neighborhood 1 having the highest count, followed by Neighborhood 2, and then Neighborhood 3. To confirm our observations, let’s display the total number of children in each neighborhood numerically.

```{r}
#| message: False
#| warning: False
#| filename: "neighborhood counts"

neighborhood_counts <- block_stacking %>%
  group_by(Neighborhood) %>% # grouping by neighborhoods
  summarize(Count = n()) %>%  # counting the number of children in each neighborhood
  arrange(desc(Count)) # arranging by number of children (descending order)
```

```{r}
#| message: False
#| warning: False
#| filename: "displaying data"

neighborhood_counts %>%
  gt()  %>% # displaying the data
  cols_label( # renaming the columns for clarity
    Count = "Number of Children"
  )
```

The summary table confirms our visual observations, showing differences in the number of children across neighborhoods. These differences suggest that the numbers may not be equal, prompting further statistical analysis to determine if the observed differences are statistically significant.

A Chi-square goodness of fit test is appropriate here because it allows us to determine whether the observed counts of children in each neighborhood differ significantly from an expected equal distribution. This test is well-suited for categorical data when comparing observed frequencies to expected frequencies under a specific hypothesis. Since we’re only interested in comparing categorical counts (number of children per neighborhood) rather than means or other continuous measures, the Chi-square test is ideal.

```{r}
#| message: False
#| warning: False
#| filename: "running Chi-square"

# running the Chi-square goodness of fit test
chisq.test(neighborhood_counts$Count, # observed counts
           p = rep(1/3, 3)) # expected (equal distribution)
```

The Chi-square goodness-of-fit test yields a p-value of 0.162. Since the p-value is greater than the typical significance level of 0.05, we **fail to reject the null hypothesis**. This suggests that there is no statistically significant evidence or sufficient evidence to conclude that the number of children in each neighborhood differ. Therefore, **the observed differences in counts could reasonably be attributed to random variation in sampling; we cannot draw any further conclusions.**

## Problem 6

To have Cube and Cylinder be seperate columns, we use `pivot_longer()` to reshape the data into a long format. We then use `mutate()` to create a new column called "Shape" that flags each shape type as either a cube or a cylinder.

```{r}
#| message: False
#| warning: False
#| filename: "tidying data"

block_stacking_long <- block_stacking %>%
  # reshaping the data to long format for visualization
  pivot_longer(cols = starts_with("Number"), # columns to pivot
               names_to = "Shape", # new column for shape type
               values_to = "Number" # new column for number of blocks
  ) %>%
  mutate( # flagging each shape type
    Shape = ifelse(Shape == "Number_Cube", "Cube", "Cylinder")
    ### this means if the shape is "Number_Cube", it's a cube, otherwise it's a cylinder
  )
```

Now that we have the data in the desired format, we can create a density plot to visualize the distribution of the number of block stackings by shape.

```{r}
#| label: fig-plot
#| message: False
#| warning: False
#| fig-alt: "Density plot showing the distribution of the number of block stackings by shape."
#| filename: "visualizing data"

# alt-text included for accessibility
ggplot(
  block_stacking_long, 
  aes(x = Number,
      fill = Shape)
  ) +
  geom_density(alpha = 0.4) + # the alpha parameter controls transparency (0.4 looks accurate)
  labs(x = "Number", 
       y = "density" # lower case "density" to match the requirements
  ) +
  theme_minimal() + 
  scale_fill_brewer(palette = "Dark2")
```

## Problem 7

We are investigating whether there is a difference in the average number of cubes and cylinders stacked by the children. The null hypothesis assumes that there is no difference in the mean number of cubes and cylinders stacked, meaning any observed difference is due to random variation.

***Null hypothesis:*** *The average number of cubes stacked is equal to the average number of cylinders stacked.*

$H_0: \mu_{\text{Cubes}} = \mu_{\text{Cylinders}}$

The alternative hypothesis represents the possibility that children stack more cubes than cylinders, suggesting that the shape of the blocks affects stacking ability. Theoretically, this is a one-sided test, as we are interested in whether cubes allow for higher stacking than cylinders, but we will perform a two-sided test for a more general comparison of means. If the sample mean is what we are interested in, we can make the one-sided conclusion.

***Alternative hypothesis:*** *The average number of cubes stacked is different from the average number of cylinders stacked.*

$H_1: \mu_{\text{Cubes}} \ne \mu_{\text{Cylinders}}$

The density plot (shown in @fig-plot) indicates that children may find it easier to stack cubes than cylinders. The distribution for cubes is shifted to the right, with more children stacking higher numbers of cubes, peaking around 8 blocks. In contrast, the distribution for cylinders has a peak at a lower value, around 5 blocks, suggesting that children stack fewer cylinders on average.

Let’s look at a numeric summary to support our observations. We’ll do so by calculating the mean and standard deviation of the number of cubes and cylinders stacked by children.

```{r}
#| message: False
#| warning: False
#| filename: "numeric summary"

summary_stats <- block_stacking_long %>% # using the long format data
  group_by(Shape) %>% # grouping by shape
  summarise(
    avg = mean(Number), # mean of number of blocks stacked
    std = sd(Number) # standard deviation of number of blocks stacked
  )
```

```{r}
#| message: False
#| warning: False
#| filename: "displaying data"

summary_stats %>% 
  gt() %>% # displaying the data
  cols_label( # renaming the columns for clarity
    Shape = "Block Type",
    avg = "Mean",
    std = "Standard Deviation"
  )
```

The numeric summary confirms the trend observed in the density plot. On average, children stack more cubes than cylinders, with a higher mean for cubes and greater variability, as shown by the standard deviation. This suggests that cubes may allow children to stack a higher number of blocks, but further statistical testing is needed to confirm if this difference is statistically significant to be applied to the population.

Since each child in the sample performed the stacking task with both cubes and cylinders, we have paired data. A paired t-test is appropriate here, as it compares the mean difference in the number of cubes and cylinders stacked for each child, taking into account the relationship between the paired measurements. This test will help us determine if the observed difference in means is statistically significant.

```{r}
#| message: False
#| warning: False
#| filename: "displaying data"

# running the paired t-test
t.test(block_stacking$Number_Cube, # number of cubes
       block_stacking$Number_Cylinder, # number of cylinders
       paired = TRUE) # specifying paired data
```

The paired t-test yields a p-value of $1.066 \times 10^{-12}$, which is well below the standard significance level of 0.05. This extremely low p-value allows us to **reject the null hypothesis** and conclude that there is a statistically significant difference in the number of cubes and cylinders stacked by children.

The paired t-test provides strong statistical evidence to conclude that children stack more cubes than cylinders on average, with a mean difference of 2.68 blocks (95% CI: 2.11 to 3.25). This finding provides strong evidence that **the shape of the blocks influences stacking ability, with cubes allowing for higher stacking than cylinders.**







