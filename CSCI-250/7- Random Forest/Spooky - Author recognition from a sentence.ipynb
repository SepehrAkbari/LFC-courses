{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c7b49c4",
   "metadata": {},
   "source": [
    "# Spooky Author Identification #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bb6e8a",
   "metadata": {},
   "source": [
    "### The aim of this project is to identify an author of spooky stories from a sentence written by them. The data for this is downloaded from here: https://www.kaggle.com/competitions/spooky-author-identification/data\n",
    "\n",
    "### This data contains 19000+ sentences written by three authors - Edgar Allan Poe (EAP), H P Lovecroft (HPL) and Mary Shelley (MWS)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51632be3",
   "metadata": {},
   "source": [
    "#### We will start by importing the modules and loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02ab14b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82ae6a4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author\n",
       "0  id26305  This process, however, afforded me no means of...    EAP\n",
       "1  id17569  It never once occurred to me that the fumbling...    HPL\n",
       "2  id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
       "3  id27763  How lovely is spring As we looked from Windsor...    MWS\n",
       "4  id12958  Finding nothing else, not even gold, the Super...    HPL"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../../old/CS 250 Data/Spooky/train.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895369a1",
   "metadata": {},
   "source": [
    "#### Next, check to see if the numbers in different classes are balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82570ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EAP    7900\n",
       "MWS    6044\n",
       "HPL    5635\n",
       "Name: author, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.author.value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac72f86",
   "metadata": {},
   "source": [
    "#### There is a slight imbalance in favor of EAP, but we will let that be for the time being since it isn't too bad. Since the data is just one column of X (sentences) and one column of Y (labels), we separate these into two numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da437ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "author = np.array(data.author)\n",
    "text = np.array(data.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fe4418",
   "metadata": {},
   "source": [
    "#### Next, we split both X and Y into training and test sets in an 80%-20% ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c13867f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15663,) (3916,) (15663,) (3916,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(text,author,test_size=0.2)\n",
    "print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b99f0e",
   "metadata": {},
   "source": [
    "# We can't, however, use these sentences directly as X!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46039cda",
   "metadata": {},
   "source": [
    "### They are all different lengths, and we can't compare them with each other. So we need to build a vocabulary.\n",
    "\n",
    "#### To do that, we need to make a list of all words used in all the sentences of the training set.  So I use a dictionary to do that. I also store their frequencies, just in case we need to know how common a word is.\n",
    "\n",
    "#### We also write a helper function, \"strip\", that takes in a word, strips all non-alphabetic characters from it (such as following commas and full stops), converts it to lowercase, and returns it. This is to prevent different versions of the same word in our vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37ec4ade",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no. of words = 23214\n"
     ]
    }
   ],
   "source": [
    "def strip(word):\n",
    "    ans = ''\n",
    "    for char in word:\n",
    "        if 'a' <= char.lower() <= 'z':\n",
    "            ans += char.lower()\n",
    "    return ans\n",
    "\n",
    "vocabulary = {}\n",
    "for line in X_train:\n",
    "    words = line.split()\n",
    "    for piece in words:\n",
    "        word = strip(piece)\n",
    "        if word in vocabulary:\n",
    "            vocabulary[word] += 1\n",
    "        else:\n",
    "            vocabulary[word] = 1\n",
    "\n",
    "print('Total no. of words =',len(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7d5c49",
   "metadata": {},
   "source": [
    "#### Our vocab has 23,000+ words. We will now represent each sentence in train and test by a histogram of these words, so each sentence is represented by an equal sized (but very sparse) vector.\n",
    "\n",
    "#### 23,000 is a little too much for the vector size, so we will discard all words that appear only once in the whole vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27f35b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of repeated words = 14249\n"
     ]
    }
   ],
   "source": [
    "## Sort the vocab by descending word frequency (not needed, just for curiosity)\n",
    "sorted_counts = sorted(vocabulary.items(), key = lambda kv: kv[1], reverse = True)\n",
    "sorted_vocab = dict(sorted_counts)\n",
    "\n",
    "## Build final vocab discarding words with frequency 1. We don't need the frequencies after this point.\n",
    "final_vocab = []\n",
    "for i in sorted_vocab.keys():  \n",
    "    if sorted_vocab[i] > 1:\n",
    "        final_vocab.append(i)\n",
    "\n",
    "        \n",
    "print('Number of repeated words =',len(final_vocab))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f65404df-d93e-409c-9a7e-7469565d396c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 28564,\n",
       " 'of': 16782,\n",
       " 'and': 14372,\n",
       " 'to': 10289,\n",
       " 'i': 8676,\n",
       " 'a': 8567,\n",
       " 'in': 7532,\n",
       " 'was': 5303,\n",
       " 'that': 5127,\n",
       " 'my': 4395,\n",
       " 'it': 3906,\n",
       " 'with': 3504,\n",
       " 'had': 3503,\n",
       " 'he': 3486,\n",
       " 'his': 3255,\n",
       " 'as': 3061,\n",
       " 'for': 2802,\n",
       " 'which': 2701,\n",
       " 'but': 2673,\n",
       " 'not': 2616,\n",
       " 'at': 2561,\n",
       " 'me': 2421,\n",
       " 'from': 2321,\n",
       " 'by': 2318,\n",
       " 'is': 2164,\n",
       " 'this': 2121,\n",
       " 'on': 1986,\n",
       " 'be': 1927,\n",
       " 'her': 1868,\n",
       " 'were': 1757,\n",
       " 'have': 1677,\n",
       " 'all': 1626,\n",
       " 'you': 1568,\n",
       " 'an': 1477,\n",
       " 'we': 1449,\n",
       " 'or': 1379,\n",
       " 'no': 1367,\n",
       " 'one': 1259,\n",
       " 'so': 1253,\n",
       " 'him': 1243,\n",
       " 'when': 1232,\n",
       " 'been': 1150,\n",
       " 'upon': 1130,\n",
       " 'they': 1108,\n",
       " 'its': 1079,\n",
       " 'there': 1055,\n",
       " 'she': 1041,\n",
       " 'could': 1031,\n",
       " 'would': 1006,\n",
       " 'more': 968,\n",
       " 'their': 926,\n",
       " 'now': 923,\n",
       " 'what': 877,\n",
       " 'some': 843,\n",
       " 'our': 804,\n",
       " 'are': 793,\n",
       " 'into': 780,\n",
       " 'who': 761,\n",
       " 'than': 760,\n",
       " 'will': 742,\n",
       " 'very': 741,\n",
       " 'if': 736,\n",
       " 'only': 707,\n",
       " 'them': 704,\n",
       " 'then': 675,\n",
       " 'before': 651,\n",
       " 'these': 642,\n",
       " 'up': 639,\n",
       " 'about': 619,\n",
       " 'man': 576,\n",
       " 'time': 574,\n",
       " 'even': 569,\n",
       " 'any': 568,\n",
       " 'did': 567,\n",
       " 'yet': 562,\n",
       " 'said': 552,\n",
       " 'out': 551,\n",
       " 'your': 550,\n",
       " 'after': 503,\n",
       " 'might': 496,\n",
       " 'like': 487,\n",
       " 'must': 485,\n",
       " 'through': 485,\n",
       " 'first': 485,\n",
       " 'most': 484,\n",
       " 'old': 482,\n",
       " 'over': 469,\n",
       " 'us': 462,\n",
       " 'made': 458,\n",
       " 'night': 458,\n",
       " '': 455,\n",
       " 'do': 446,\n",
       " 'never': 445,\n",
       " 'life': 445,\n",
       " 'should': 444,\n",
       " 'such': 441,\n",
       " 'eyes': 438,\n",
       " 'other': 436,\n",
       " 'found': 435,\n",
       " 'seemed': 431,\n",
       " 'every': 422,\n",
       " 'little': 422,\n",
       " 'saw': 415,\n",
       " 'long': 412,\n",
       " 'still': 410,\n",
       " 'has': 410,\n",
       " 'great': 410,\n",
       " 'those': 409,\n",
       " 'while': 408,\n",
       " 'myself': 407,\n",
       " 'many': 407,\n",
       " 'day': 403,\n",
       " 'where': 402,\n",
       " 'own': 398,\n",
       " 'again': 394,\n",
       " 'much': 373,\n",
       " 'well': 367,\n",
       " 'down': 366,\n",
       " 'may': 362,\n",
       " 'thought': 357,\n",
       " 'came': 357,\n",
       " 'can': 354,\n",
       " 'being': 350,\n",
       " 'two': 346,\n",
       " 'here': 345,\n",
       " 'once': 342,\n",
       " 'ever': 337,\n",
       " 'how': 337,\n",
       " 'am': 330,\n",
       " 'say': 327,\n",
       " 'see': 322,\n",
       " 'thus': 322,\n",
       " 'death': 316,\n",
       " 'without': 311,\n",
       " 'too': 309,\n",
       " 'whose': 306,\n",
       " 'heart': 305,\n",
       " 'mind': 304,\n",
       " 'shall': 304,\n",
       " 'far': 297,\n",
       " 'house': 293,\n",
       " 'however': 292,\n",
       " 'things': 289,\n",
       " 'thing': 284,\n",
       " 'men': 280,\n",
       " 'heard': 280,\n",
       " 'left': 280,\n",
       " 'last': 276,\n",
       " 'know': 275,\n",
       " 'years': 275,\n",
       " 'place': 275,\n",
       " 'felt': 272,\n",
       " 'himself': 262,\n",
       " 'love': 258,\n",
       " 'few': 254,\n",
       " 'indeed': 253,\n",
       " 'though': 252,\n",
       " 'let': 248,\n",
       " 'whole': 248,\n",
       " 'world': 247,\n",
       " 'within': 247,\n",
       " 'come': 245,\n",
       " 'way': 245,\n",
       " 'earth': 244,\n",
       " 'door': 243,\n",
       " 'light': 242,\n",
       " 'became': 238,\n",
       " 'having': 237,\n",
       " 'nothing': 236,\n",
       " 'words': 236,\n",
       " 'room': 235,\n",
       " 'head': 234,\n",
       " 'seen': 231,\n",
       " 'among': 231,\n",
       " 'nature': 231,\n",
       " 'back': 229,\n",
       " 'hand': 229,\n",
       " 'human': 228,\n",
       " 'under': 228,\n",
       " 'strange': 228,\n",
       " 'nor': 227,\n",
       " 'voice': 226,\n",
       " 'each': 225,\n",
       " 'make': 223,\n",
       " 'away': 220,\n",
       " 'good': 216,\n",
       " 'knew': 215,\n",
       " 'same': 214,\n",
       " 'length': 212,\n",
       " 'during': 211,\n",
       " 'half': 211,\n",
       " 'three': 209,\n",
       " 'new': 209,\n",
       " 'another': 205,\n",
       " 'alone': 205,\n",
       " 'off': 204,\n",
       " 'soon': 203,\n",
       " 'although': 203,\n",
       " 'friend': 202,\n",
       " 'beyond': 201,\n",
       " 'raymond': 201,\n",
       " 'part': 201,\n",
       " 'since': 200,\n",
       " 'sea': 200,\n",
       " 'moment': 198,\n",
       " 'less': 197,\n",
       " 'fear': 197,\n",
       " 'air': 192,\n",
       " 'above': 191,\n",
       " 'soul': 190,\n",
       " 'almost': 188,\n",
       " 'full': 187,\n",
       " 'just': 186,\n",
       " 'looked': 185,\n",
       " 'small': 184,\n",
       " 'days': 183,\n",
       " 'why': 183,\n",
       " 'father': 182,\n",
       " 'dark': 182,\n",
       " 'near': 181,\n",
       " 'gave': 180,\n",
       " 'young': 179,\n",
       " 'went': 179,\n",
       " 'whom': 178,\n",
       " 'city': 178,\n",
       " 'certain': 178,\n",
       " 'find': 178,\n",
       " 'around': 178,\n",
       " 'body': 177,\n",
       " 'passed': 177,\n",
       " 'lay': 175,\n",
       " 'told': 174,\n",
       " 'something': 174,\n",
       " 'took': 173,\n",
       " 'spirit': 171,\n",
       " 'high': 171,\n",
       " 'face': 170,\n",
       " 'also': 169,\n",
       " 'open': 169,\n",
       " 'mr': 168,\n",
       " 'itself': 168,\n",
       " 'end': 167,\n",
       " 'take': 166,\n",
       " 'think': 166,\n",
       " 'go': 165,\n",
       " 'appeared': 165,\n",
       " 'perhaps': 163,\n",
       " 'until': 161,\n",
       " 'course': 159,\n",
       " 'black': 158,\n",
       " 'point': 157,\n",
       " 'water': 157,\n",
       " 'between': 156,\n",
       " 'rather': 156,\n",
       " 'hope': 155,\n",
       " 'feet': 155,\n",
       " 'matter': 155,\n",
       " 'deep': 153,\n",
       " 'idea': 153,\n",
       " 'dead': 152,\n",
       " 'horror': 151,\n",
       " 'known': 151,\n",
       " 'hours': 151,\n",
       " 'least': 150,\n",
       " 'feel': 150,\n",
       " 'name': 148,\n",
       " 'began': 146,\n",
       " 'moon': 146,\n",
       " 'tell': 145,\n",
       " 'cannot': 145,\n",
       " 'street': 144,\n",
       " 'form': 144,\n",
       " 'lost': 144,\n",
       " 'called': 144,\n",
       " 'right': 144,\n",
       " 'power': 144,\n",
       " 'turned': 144,\n",
       " 'scene': 143,\n",
       " 'side': 143,\n",
       " 'manner': 142,\n",
       " 'because': 141,\n",
       " 'nearly': 139,\n",
       " 'sometimes': 139,\n",
       " 'doubt': 139,\n",
       " 'kind': 138,\n",
       " 'o': 138,\n",
       " 'means': 137,\n",
       " 'look': 137,\n",
       " 'spoke': 136,\n",
       " 'often': 135,\n",
       " 'morning': 135,\n",
       " 'taken': 135,\n",
       " 'ancient': 135,\n",
       " 'present': 134,\n",
       " 'hands': 134,\n",
       " 'become': 134,\n",
       " 'brought': 133,\n",
       " 'sun': 132,\n",
       " 'towards': 132,\n",
       " 'beauty': 131,\n",
       " 'general': 131,\n",
       " 'sound': 131,\n",
       " 'object': 130,\n",
       " 'return': 130,\n",
       " 'home': 130,\n",
       " 'several': 129,\n",
       " 'second': 129,\n",
       " 'perdita': 128,\n",
       " 'both': 128,\n",
       " 'wild': 128,\n",
       " 'true': 128,\n",
       " 'put': 127,\n",
       " 'against': 127,\n",
       " 'country': 127,\n",
       " 'thousand': 127,\n",
       " 'fact': 127,\n",
       " 'hour': 126,\n",
       " 'entered': 126,\n",
       " 'people': 125,\n",
       " 'suddenly': 125,\n",
       " 'reason': 125,\n",
       " 'better': 124,\n",
       " 'eye': 124,\n",
       " 'always': 124,\n",
       " 'longer': 124,\n",
       " 'sight': 123,\n",
       " 'town': 123,\n",
       " 'continued': 122,\n",
       " 'set': 122,\n",
       " 'de': 122,\n",
       " 'grew': 121,\n",
       " 'work': 121,\n",
       " 'person': 120,\n",
       " 'fell': 120,\n",
       " 'large': 120,\n",
       " 'stood': 119,\n",
       " 'state': 119,\n",
       " 'terrible': 119,\n",
       " 'give': 118,\n",
       " 'others': 118,\n",
       " 'dream': 117,\n",
       " 'truth': 116,\n",
       " 'sleep': 115,\n",
       " 'dreams': 115,\n",
       " 'believe': 114,\n",
       " 'case': 114,\n",
       " 'family': 114,\n",
       " 'remained': 114,\n",
       " 'quite': 113,\n",
       " 'toward': 113,\n",
       " 'beneath': 113,\n",
       " 'already': 113,\n",
       " 'attention': 112,\n",
       " 'word': 112,\n",
       " 'period': 111,\n",
       " 'white': 111,\n",
       " 'dear': 110,\n",
       " 'poor': 110,\n",
       " 'evil': 109,\n",
       " 'past': 109,\n",
       " 'thoughts': 109,\n",
       " 'ground': 109,\n",
       " 'possible': 109,\n",
       " 'appearance': 109,\n",
       " 'unknown': 109,\n",
       " 'times': 109,\n",
       " 'trees': 109,\n",
       " 'speak': 109,\n",
       " 'sense': 108,\n",
       " 'vast': 108,\n",
       " 'tears': 108,\n",
       " 'read': 108,\n",
       " 'account': 107,\n",
       " 'given': 107,\n",
       " 'done': 106,\n",
       " 'change': 106,\n",
       " 'either': 106,\n",
       " 'god': 106,\n",
       " 'character': 105,\n",
       " 'close': 105,\n",
       " 'wind': 105,\n",
       " 'west': 105,\n",
       " 'looking': 105,\n",
       " 'died': 105,\n",
       " 'floor': 104,\n",
       " 'despair': 104,\n",
       " 'led': 104,\n",
       " 'themselves': 103,\n",
       " 'view': 103,\n",
       " 'low': 103,\n",
       " 'next': 103,\n",
       " 'none': 102,\n",
       " 'immediately': 102,\n",
       " 'child': 102,\n",
       " 'oh': 102,\n",
       " 'stone': 101,\n",
       " 'window': 101,\n",
       " 'adrian': 101,\n",
       " 'happy': 101,\n",
       " 'till': 101,\n",
       " 'sat': 101,\n",
       " 'chamber': 100,\n",
       " 'cold': 100,\n",
       " 'mother': 99,\n",
       " 'countenance': 99,\n",
       " 'therefore': 99,\n",
       " 'walls': 98,\n",
       " 'best': 98,\n",
       " 'mere': 98,\n",
       " 'sure': 98,\n",
       " 'friends': 97,\n",
       " 'together': 97,\n",
       " 'happiness': 97,\n",
       " 'question': 97,\n",
       " 'interest': 96,\n",
       " 'replied': 95,\n",
       " 'enough': 95,\n",
       " 'wonder': 95,\n",
       " 'space': 94,\n",
       " 'evening': 93,\n",
       " 'gone': 93,\n",
       " 'blood': 93,\n",
       " 'hideous': 93,\n",
       " 'secret': 93,\n",
       " 'misery': 92,\n",
       " 'land': 92,\n",
       " 'five': 92,\n",
       " 'age': 92,\n",
       " 'gentle': 92,\n",
       " 'existence': 92,\n",
       " 'england': 92,\n",
       " 'feelings': 92,\n",
       " 'merely': 91,\n",
       " 'imagination': 91,\n",
       " 'four': 91,\n",
       " 'get': 91,\n",
       " 'leave': 91,\n",
       " 'held': 90,\n",
       " 'feeling': 90,\n",
       " 'idris': 90,\n",
       " 'late': 90,\n",
       " 'memory': 90,\n",
       " 'circumstances': 90,\n",
       " 'observed': 89,\n",
       " 'degree': 89,\n",
       " 'latter': 89,\n",
       " 'hear': 89,\n",
       " 'greater': 89,\n",
       " 'knowledge': 89,\n",
       " 'wish': 89,\n",
       " 'fellow': 89,\n",
       " 'neither': 89,\n",
       " 'rest': 88,\n",
       " 'call': 88,\n",
       " 'heaven': 88,\n",
       " 'filled': 88,\n",
       " 'returned': 88,\n",
       " 'expression': 88,\n",
       " 'forth': 88,\n",
       " 'short': 88,\n",
       " 'behind': 88,\n",
       " 'discovered': 87,\n",
       " 'below': 87,\n",
       " 'shadow': 87,\n",
       " 'wall': 87,\n",
       " 'natural': 86,\n",
       " 'windows': 86,\n",
       " 'portion': 86,\n",
       " 'reached': 85,\n",
       " 'altogether': 85,\n",
       " 'care': 85,\n",
       " 'remember': 85,\n",
       " 'cause': 85,\n",
       " 'really': 84,\n",
       " 'sought': 84,\n",
       " 'distance': 84,\n",
       " 'sky': 84,\n",
       " 'living': 84,\n",
       " 'purpose': 83,\n",
       " 'river': 83,\n",
       " 'youth': 83,\n",
       " 'formed': 83,\n",
       " 'lips': 83,\n",
       " 'herself': 82,\n",
       " 'green': 82,\n",
       " 'year': 82,\n",
       " 'die': 82,\n",
       " 'arms': 82,\n",
       " 'corpse': 82,\n",
       " 'lady': 81,\n",
       " 'loved': 81,\n",
       " 'children': 81,\n",
       " 'mine': 81,\n",
       " 'joy': 81,\n",
       " 'necessary': 81,\n",
       " 'along': 81,\n",
       " 'houses': 80,\n",
       " 'self': 80,\n",
       " 'peculiar': 80,\n",
       " 'subject': 80,\n",
       " 'table': 80,\n",
       " 'difficulty': 80,\n",
       " 'ill': 80,\n",
       " 'sir': 79,\n",
       " 'letter': 79,\n",
       " 'fire': 79,\n",
       " 'save': 78,\n",
       " 'steps': 78,\n",
       " 'arm': 78,\n",
       " 'terror': 78,\n",
       " 'silence': 78,\n",
       " 'somewhat': 77,\n",
       " 'sweet': 77,\n",
       " 'followed': 77,\n",
       " 'mountain': 77,\n",
       " 'hills': 77,\n",
       " 'darkness': 77,\n",
       " 'scarcely': 77,\n",
       " 'months': 77,\n",
       " 'possessed': 77,\n",
       " 'box': 76,\n",
       " 'spot': 76,\n",
       " 'impossible': 76,\n",
       " 'wide': 76,\n",
       " 'order': 76,\n",
       " 'fancy': 76,\n",
       " 'early': 76,\n",
       " 'minutes': 76,\n",
       " 'kept': 76,\n",
       " 'grave': 75,\n",
       " 'beautiful': 75,\n",
       " 'heavy': 75,\n",
       " 'common': 75,\n",
       " 'resolved': 75,\n",
       " 'mad': 74,\n",
       " 'especially': 74,\n",
       " 'grief': 74,\n",
       " 'bed': 74,\n",
       " 'cast': 74,\n",
       " 'use': 74,\n",
       " 'hair': 74,\n",
       " 'beheld': 73,\n",
       " 'dr': 73,\n",
       " 'arose': 73,\n",
       " 'ten': 73,\n",
       " 'ye': 73,\n",
       " 'opened': 73,\n",
       " 'singular': 73,\n",
       " 'affection': 72,\n",
       " 'caused': 72,\n",
       " 'instant': 72,\n",
       " 'live': 72,\n",
       " 'book': 72,\n",
       " 'entirely': 72,\n",
       " 'woman': 72,\n",
       " 'twenty': 72,\n",
       " 'later': 72,\n",
       " 'figure': 72,\n",
       " 'easily': 71,\n",
       " 'received': 71,\n",
       " 'round': 71,\n",
       " 'books': 71,\n",
       " 'proceeded': 70,\n",
       " 'boat': 70,\n",
       " 'surface': 70,\n",
       " 'escape': 70,\n",
       " 'narrow': 70,\n",
       " 'placed': 70,\n",
       " 'slight': 70,\n",
       " 'born': 70,\n",
       " 'hill': 70,\n",
       " 'former': 70,\n",
       " 'presence': 69,\n",
       " 'effect': 69,\n",
       " 'wife': 69,\n",
       " 'distant': 69,\n",
       " 'finally': 69,\n",
       " 'sister': 69,\n",
       " 'line': 69,\n",
       " 'rose': 69,\n",
       " 'turn': 69,\n",
       " 'across': 69,\n",
       " 'direction': 69,\n",
       " 'met': 69,\n",
       " 'force': 68,\n",
       " 'does': 68,\n",
       " 'pleasure': 68,\n",
       " 'lived': 68,\n",
       " 'paper': 68,\n",
       " 'sorrow': 68,\n",
       " 'sounds': 68,\n",
       " 'strength': 67,\n",
       " 'asked': 67,\n",
       " 'windsor': 67,\n",
       " 'stars': 67,\n",
       " 'delight': 67,\n",
       " 'thrown': 67,\n",
       " 'north': 67,\n",
       " 'coming': 67,\n",
       " 'lovely': 67,\n",
       " 'thou': 66,\n",
       " 'anything': 66,\n",
       " 'fate': 66,\n",
       " 'silent': 66,\n",
       " 'understand': 66,\n",
       " 'london': 66,\n",
       " 'cottage': 65,\n",
       " 'valley': 65,\n",
       " 'struck': 65,\n",
       " 'hopes': 65,\n",
       " 'company': 65,\n",
       " 'plague': 65,\n",
       " 'influence': 65,\n",
       " 'usual': 65,\n",
       " 'east': 65,\n",
       " 'says': 65,\n",
       " 'broken': 65,\n",
       " 'm': 65,\n",
       " 'future': 64,\n",
       " 'balloon': 64,\n",
       " 'third': 64,\n",
       " 'regard': 64,\n",
       " 'party': 64,\n",
       " 'visible': 64,\n",
       " 'whether': 64,\n",
       " 'excited': 64,\n",
       " 'streets': 64,\n",
       " 'fallen': 64,\n",
       " 'apparently': 64,\n",
       " 'desire': 64,\n",
       " 'cut': 64,\n",
       " 'various': 64,\n",
       " 'fully': 63,\n",
       " 'real': 63,\n",
       " 'pain': 63,\n",
       " 'making': 63,\n",
       " 'red': 63,\n",
       " 'society': 63,\n",
       " 'changed': 63,\n",
       " 'tried': 63,\n",
       " 'ordinary': 63,\n",
       " 'girl': 63,\n",
       " 'wished': 63,\n",
       " 'clear': 63,\n",
       " 'gods': 63,\n",
       " 'ice': 62,\n",
       " 'atmosphere': 62,\n",
       " 'beloved': 62,\n",
       " 'position': 62,\n",
       " 'hold': 62,\n",
       " 'drew': 62,\n",
       " 'events': 62,\n",
       " 'ago': 61,\n",
       " 'objects': 61,\n",
       " 'alas': 61,\n",
       " 'road': 61,\n",
       " 'tale': 61,\n",
       " 'appear': 61,\n",
       " 'uncle': 61,\n",
       " 'got': 61,\n",
       " 'madame': 61,\n",
       " 'utterly': 61,\n",
       " 'ship': 60,\n",
       " 'bring': 60,\n",
       " 'closed': 60,\n",
       " 'machine': 60,\n",
       " 'ocean': 60,\n",
       " 'hundred': 60,\n",
       " 'going': 60,\n",
       " 'art': 60,\n",
       " 'six': 60,\n",
       " 'extent': 60,\n",
       " 'condition': 60,\n",
       " 'simple': 60,\n",
       " 'frame': 60,\n",
       " 'calm': 60,\n",
       " 'hung': 59,\n",
       " 'threw': 59,\n",
       " 'mountains': 59,\n",
       " 'main': 59,\n",
       " 'tomb': 59,\n",
       " 'south': 59,\n",
       " 'wood': 59,\n",
       " 'blue': 59,\n",
       " 'elizabeth': 59,\n",
       " 'top': 59,\n",
       " 'shore': 59,\n",
       " 'passion': 59,\n",
       " 'single': 59,\n",
       " 'vain': 59,\n",
       " 'free': 59,\n",
       " 'design': 58,\n",
       " 'faint': 58,\n",
       " 'want': 58,\n",
       " 'discovery': 58,\n",
       " 'prepared': 58,\n",
       " 'vague': 58,\n",
       " 'miserable': 58,\n",
       " 'dont': 58,\n",
       " 'business': 58,\n",
       " 'native': 58,\n",
       " 'else': 58,\n",
       " 'yes': 58,\n",
       " 'visit': 57,\n",
       " 'spent': 57,\n",
       " 'cried': 57,\n",
       " 'alive': 57,\n",
       " 'odd': 57,\n",
       " 'extreme': 57,\n",
       " 'help': 57,\n",
       " 'motion': 57,\n",
       " 'perceive': 57,\n",
       " 'seek': 57,\n",
       " 'arrived': 57,\n",
       " 'perceived': 57,\n",
       " 'entire': 57,\n",
       " 'certainly': 57,\n",
       " 'besides': 57,\n",
       " 'taking': 56,\n",
       " 'companion': 56,\n",
       " 'expected': 56,\n",
       " 'hardly': 56,\n",
       " 'mean': 56,\n",
       " 'yourself': 56,\n",
       " 'winter': 56,\n",
       " 'sufficient': 56,\n",
       " 'public': 56,\n",
       " 'horrible': 56,\n",
       " 'queer': 56,\n",
       " 'apparent': 56,\n",
       " 'pale': 56,\n",
       " 'dared': 56,\n",
       " 'forest': 55,\n",
       " 'result': 55,\n",
       " 'progress': 55,\n",
       " 'health': 55,\n",
       " 'bore': 55,\n",
       " 'madness': 55,\n",
       " 'keep': 55,\n",
       " 'absence': 55,\n",
       " 'sympathy': 55,\n",
       " 'ears': 55,\n",
       " 'fearful': 55,\n",
       " 'st': 55,\n",
       " 'lord': 55,\n",
       " 'mentioned': 55,\n",
       " 'supposed': 55,\n",
       " 'act': 54,\n",
       " 'rain': 54,\n",
       " 'height': 54,\n",
       " 'outside': 54,\n",
       " 'waters': 54,\n",
       " 'fall': 54,\n",
       " 'occupied': 54,\n",
       " 'deserted': 54,\n",
       " 'considered': 54,\n",
       " 'curiosity': 54,\n",
       " 'able': 54,\n",
       " 'passage': 54,\n",
       " 'occurred': 54,\n",
       " 'except': 53,\n",
       " 'remembered': 53,\n",
       " 'evidently': 53,\n",
       " 'story': 53,\n",
       " 'forgotten': 53,\n",
       " 'agony': 53,\n",
       " 'covered': 53,\n",
       " 'reality': 53,\n",
       " 'apartment': 53,\n",
       " 'courage': 53,\n",
       " 'tree': 53,\n",
       " 'moved': 53,\n",
       " 'melancholy': 53,\n",
       " 'rise': 52,\n",
       " 'music': 52,\n",
       " 'bottom': 52,\n",
       " 'frightful': 52,\n",
       " 'attempt': 52,\n",
       " 'sort': 52,\n",
       " 'different': 52,\n",
       " 'rendered': 52,\n",
       " 'whilst': 52,\n",
       " 'strong': 52,\n",
       " 'approached': 52,\n",
       " 'path': 52,\n",
       " 'gentleman': 52,\n",
       " 'suffered': 51,\n",
       " 'features': 51,\n",
       " 'ones': 51,\n",
       " 'sole': 51,\n",
       " 'reach': 51,\n",
       " 'plain': 51,\n",
       " 'ceased': 51,\n",
       " 'fresh': 51,\n",
       " 'learned': 51,\n",
       " 'rock': 51,\n",
       " 'seem': 51,\n",
       " 'island': 51,\n",
       " 'concerning': 51,\n",
       " 'number': 51,\n",
       " 'danger': 51,\n",
       " 'immediate': 51,\n",
       " 'possession': 50,\n",
       " 'task': 50,\n",
       " 'talk': 50,\n",
       " 'foot': 50,\n",
       " 'exceedingly': 50,\n",
       " 'remain': 50,\n",
       " 'miles': 50,\n",
       " 'places': 50,\n",
       " 'bear': 50,\n",
       " 'fine': 50,\n",
       " 'determined': 50,\n",
       " 'action': 50,\n",
       " 'creature': 49,\n",
       " 'marble': 49,\n",
       " 'walked': 49,\n",
       " 'forms': 49,\n",
       " 'evidence': 49,\n",
       " 'creatures': 49,\n",
       " 'castle': 49,\n",
       " 'success': 49,\n",
       " 'added': 49,\n",
       " 'boy': 49,\n",
       " 'mouth': 49,\n",
       " 'seems': 49,\n",
       " 'intense': 49,\n",
       " 'glance': 49,\n",
       " 'son': 49,\n",
       " 'forever': 49,\n",
       " 'gazed': 49,\n",
       " 'persons': 49,\n",
       " 'fair': 48,\n",
       " 'perfect': 48,\n",
       " 'week': 48,\n",
       " 'village': 48,\n",
       " 'ran': 48,\n",
       " 'fears': 48,\n",
       " 'need': 48,\n",
       " 'golden': 48,\n",
       " 'brief': 48,\n",
       " 'ideas': 48,\n",
       " 'watch': 48,\n",
       " 'senses': 48,\n",
       " 'flowers': 48,\n",
       " 'vision': 48,\n",
       " 'arkham': 48,\n",
       " 'remarkable': 48,\n",
       " 'remote': 48,\n",
       " 'breath': 48,\n",
       " 'peace': 48,\n",
       " 'weight': 48,\n",
       " 'conversation': 48,\n",
       " 'gold': 48,\n",
       " 'material': 47,\n",
       " 'smile': 47,\n",
       " 'slept': 47,\n",
       " 'noble': 47,\n",
       " 'talked': 47,\n",
       " 'language': 47,\n",
       " 'promise': 47,\n",
       " 'heavens': 47,\n",
       " 'similar': 47,\n",
       " 'spread': 47,\n",
       " 'english': 47,\n",
       " 'greatest': 47,\n",
       " 'beings': 47,\n",
       " 'oclock': 47,\n",
       " 'eight': 47,\n",
       " 'thy': 47,\n",
       " 'believed': 47,\n",
       " 'respect': 47,\n",
       " 'answer': 47,\n",
       " 'spring': 47,\n",
       " 'clouds': 47,\n",
       " 'horizon': 47,\n",
       " 'reply': 47,\n",
       " 'sufficiently': 47,\n",
       " 'succeeded': 47,\n",
       " 'building': 47,\n",
       " 'destroyed': 47,\n",
       " 'sent': 47,\n",
       " 'familiar': 46,\n",
       " 'solitude': 46,\n",
       " 'following': 46,\n",
       " 'journey': 46,\n",
       " 'circumstance': 46,\n",
       " 'situation': 46,\n",
       " 'lake': 46,\n",
       " 'fathers': 46,\n",
       " 'carried': 46,\n",
       " 'spirits': 46,\n",
       " 'star': 46,\n",
       " 'pocket': 46,\n",
       " 'dupin': 46,\n",
       " 'distinct': 46,\n",
       " 'brain': 46,\n",
       " 'visited': 46,\n",
       " 'huge': 46,\n",
       " 'opinion': 46,\n",
       " 'original': 46,\n",
       " 'lead': 46,\n",
       " 'moments': 46,\n",
       " 'bent': 46,\n",
       " 'leaving': 46,\n",
       " 'dying': 46,\n",
       " 'ghastly': 46,\n",
       " 'inhabitants': 46,\n",
       " 'listened': 46,\n",
       " 'storm': 46,\n",
       " 'powers': 46,\n",
       " 'mystery': 46,\n",
       " 'key': 46,\n",
       " 'afterward': 46,\n",
       " 'evident': 45,\n",
       " 'feeble': 45,\n",
       " 'write': 45,\n",
       " 'proved': 45,\n",
       " 'summer': 45,\n",
       " 'occasion': 45,\n",
       " 'daughter': 45,\n",
       " 'aware': 45,\n",
       " 'seven': 45,\n",
       " 'sudden': 45,\n",
       " 'seized': 45,\n",
       " 'individual': 45,\n",
       " 'probably': 45,\n",
       " 'mighty': 45,\n",
       " 'piece': 45,\n",
       " 'slowly': 45,\n",
       " 'nose': 45,\n",
       " 'notice': 45,\n",
       " 'quiet': 45,\n",
       " 'quickly': 45,\n",
       " 'marked': 45,\n",
       " 'greatly': 45,\n",
       " 'increased': 45,\n",
       " 'unusual': 44,\n",
       " 'car': 44,\n",
       " 'enter': 44,\n",
       " 'tall': 44,\n",
       " 'suppose': 44,\n",
       " 'palace': 44,\n",
       " 'failed': 44,\n",
       " 'buried': 44,\n",
       " 'innsmouth': 44,\n",
       " 'describe': 44,\n",
       " 'aspect': 44,\n",
       " 'midnight': 44,\n",
       " 'shewed': 44,\n",
       " 'region': 44,\n",
       " 'size': 44,\n",
       " 'amidst': 44,\n",
       " 'disease': 44,\n",
       " 'rich': 44,\n",
       " 'dare': 44,\n",
       " 'used': 44,\n",
       " 'unable': 44,\n",
       " 'follow': 44,\n",
       " 'search': 44,\n",
       " 'pass': 44,\n",
       " 'monstrous': 43,\n",
       " 'study': 43,\n",
       " 'proper': 43,\n",
       " 'glass': 43,\n",
       " 'sad': 43,\n",
       " 'actually': 43,\n",
       " 'hard': 43,\n",
       " 'thin': 43,\n",
       " 'burst': 43,\n",
       " 'presented': 43,\n",
       " 'big': 43,\n",
       " 'greek': 43,\n",
       " 'mansion': 43,\n",
       " 'mental': 43,\n",
       " 'board': 43,\n",
       " 'grown': 43,\n",
       " 'minute': 43,\n",
       " 'meet': 43,\n",
       " 'crowd': 43,\n",
       " 'trace': 43,\n",
       " 'degrees': 43,\n",
       " 'vessel': 43,\n",
       " 'faces': 43,\n",
       " 'relief': 43,\n",
       " 'step': 43,\n",
       " 'hall': 42,\n",
       " 'imagine': 42,\n",
       " 'chair': 42,\n",
       " 'curious': 42,\n",
       " 'meantime': 42,\n",
       " 'gilman': 42,\n",
       " 'grey': 42,\n",
       " 'understood': 42,\n",
       " 'despite': 42,\n",
       " 'wholly': 42,\n",
       " 'carefully': 42,\n",
       " 'thee': 42,\n",
       " 'behold': 42,\n",
       " 'bitter': 42,\n",
       " ...}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1851679f",
   "metadata": {},
   "source": [
    "#### So the size of our vocabulary is 14362. Next, we will convert our whole training (and test) sets into extremely sparse histograms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e62d7187",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainData = np.zeros((X_train.shape[0],len(final_vocab)),'uint16')\n",
    "for i in range(trainData.shape[0]):\n",
    "    words = X_train[i].split()\n",
    "    for j in range(len(words)):\n",
    "        token = strip(words[j])\n",
    "        if token in final_vocab:\n",
    "            trainData[i,final_vocab.index(token)] += 1\n",
    "        \n",
    "testData = np.zeros((X_test.shape[0],len(final_vocab)),'uint16')\n",
    "for i in range(testData.shape[0]):\n",
    "    words = X_test[i].split()\n",
    "    for j in range(len(words)):\n",
    "        token = strip(words[j])\n",
    "        if token in final_vocab:\n",
    "            testData[i,final_vocab.index(token)] += 1\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1d95594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training data: (15663, 14249)\n",
      "Size of test data: (3916, 14249)\n"
     ]
    }
   ],
   "source": [
    "print('Size of training data:',trainData.shape)\n",
    "print('Size of test data:',testData.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcb0695",
   "metadata": {},
   "source": [
    "### Now we will try a few classification methods on this data - Logistic Regression, SVM and Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "995c0070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regressor...done!\n",
      "Training Support Vector Machine...done!\n",
      "Training Random Forest Regressor..."
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 26>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining Random Forest Regressor\u001b[39m\u001b[38;5;124m'\u001b[39m,end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     25\u001b[0m model_RF \u001b[38;5;241m=\u001b[39m RandomForestRegressor(n_estimators\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 26\u001b[0m \u001b[43mmodel_RF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainData\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainLabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdone!\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:450\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    439\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    440\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    441\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    442\u001b[0m ]\n\u001b[0;32m    444\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 450\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_joblib_parallel_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    464\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1044\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1046\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1047\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1050\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1052\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 861\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    778\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 779\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    781\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:185\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    183\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 185\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    187\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:1315\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\n\u001b[0;32m   1279\u001b[0m     \u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, X_idx_sorted\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1280\u001b[0m ):\n\u001b[0;32m   1281\u001b[0m     \u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1282\u001b[0m \n\u001b[0;32m   1283\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1312\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1313\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1315\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1317\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1318\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_idx_sorted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_idx_sorted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1321\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1322\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:420\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    410\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    411\u001b[0m         splitter,\n\u001b[0;32m    412\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    417\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    418\u001b[0m     )\n\u001b[1;32m--> 420\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    423\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "print('Training Logistic Regressor',end='...')\n",
    "model_LR = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial',max_iter=1000)\n",
    "model_LR.fit(trainData, y_train)\n",
    "print('done!')\n",
    "\n",
    "print('Training Support Vector Machine',end='...')\n",
    "model_SVM = svm.LinearSVC(max_iter=5000)\n",
    "model_SVM.fit(trainData, y_train)\n",
    "print('done!')\n",
    "\n",
    "# Random forest needs numerical labels - so converting string labels to numbers\n",
    "labelStrings = ['EAP' , 'HPL' , 'MWS']\n",
    "trainLabels = []\n",
    "testLabels = []\n",
    "for label in y_train:\n",
    "    trainLabels.append(labelStrings.index(label))\n",
    "for label in y_test:\n",
    "    testLabels.append(labelStrings.index(label))\n",
    "\n",
    "print('Training Random Forest Regressor',end='...')\n",
    "model_RF = RandomForestRegressor(n_estimators= 10, random_state=42)\n",
    "model_RF.fit(trainData, trainLabels)\n",
    "print('done!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44866b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run models on test data\n",
    "print('Test data performance:\\n')\n",
    "print('Logistic Regressor score :',model_LR.score(testData, y_test))\n",
    "print('SVM score :',model_SVM.score(testData, y_test))\n",
    "print('Random Forest score :',model_RF.score(testData, testLabels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb7bd24",
   "metadata": {},
   "source": [
    "#### Just to find out how much the models are learning, we also check the performances on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f7ae101c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data performance:\n",
      "\n",
      "Logistic Regressor score : 0.9784843261188789\n",
      "SVM score : 0.9933601481197727\n",
      "Random Forest score : 0.8683445027371611\n"
     ]
    }
   ],
   "source": [
    "#Run models on training data\n",
    "print('Training data performance:\\n')\n",
    "print('Logistic Regressor score :',model_LR.score(trainData, y_train))\n",
    "print('SVM score :',model_SVM.score(trainData, y_train))\n",
    "print('Random Forest score :',model_RF.score(trainData, trainLabels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a064ceb",
   "metadata": {},
   "source": [
    "#### We find the Logistic Regressor gives the best score, whereas the Random Forest has severe overfitting.\n",
    "\n",
    "#### We use this best model to further create a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f84d0a62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualize performance by Normalized confusion matrix\n",
    "import seaborn as sn\n",
    "numClasses = 3\n",
    "classes = ['EAP','HPL','MWS']\n",
    "\n",
    "conf = np.zeros([numClasses,numClasses])\n",
    "guesses = model_LR.predict(testData)\n",
    "\n",
    "for s in range(testData.shape[0]):\n",
    "    real = classes.index(y_test[s])\n",
    "    guess = classes.index(guesses[s])\n",
    "    conf[real,guess] = conf[real,guess] + 1\n",
    " \n",
    "rowsums = np.sum(conf,1)\n",
    "rowsums = np.reshape(rowsums,[numClasses,1])\n",
    "rowsums = np.repeat(rowsums,numClasses, axis = 1)\n",
    "conf = conf / rowsums\n",
    "df_cm = pd.DataFrame(conf, index = [i for i in classes],\n",
    "                  columns = [i for i in classes])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fdbaaa",
   "metadata": {},
   "source": [
    "### Our vectors are terrible... extremely sparse and huge. We will try to reduce their dimensionality using PCA and see how that affects the classification scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc76d7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "scaler=StandardScaler()\n",
    "normtrain = scaler.fit_transform(trainData)\n",
    "normtest = scaler.fit_transform(testData)\n",
    "\n",
    "pca = PCA(n_components=500,whiten=True)\n",
    "lowtrain = pca.fit_transform(normtrain)\n",
    "lowtest = pca.transform(normtest)\n",
    "\n",
    "print('Training and test data shape after dimensionality reduction:',lowtrain.shape,lowtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c81c03d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regressor...done!\n",
      "Training Support Vector Machine..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\sbane\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n",
      "Training Random Forest Regressor...done!\n"
     ]
    }
   ],
   "source": [
    "print('Training Logistic Regressor',end='...')\n",
    "model_LR2 = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial',max_iter=1000)\n",
    "model_LR2.fit(lowtrain, y_train)\n",
    "print('done!')\n",
    "\n",
    "print('Training Support Vector Machine',end='...')\n",
    "model_SVM2 = svm.LinearSVC(max_iter=5000)\n",
    "model_SVM2.fit(lowtrain, y_train)\n",
    "print('done!')\n",
    "\n",
    "print('Training Random Forest Regressor',end='...')\n",
    "model_RF2 = RandomForestRegressor(n_estimators= 10, random_state=42)\n",
    "model_RF2.fit(lowtrain, trainLabels)\n",
    "print('done!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "080be1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data performance:\n",
      "\n",
      "Logistic Regressor score : 0.7957099080694586\n",
      "SVM score : 0.7908580183861083\n",
      "Random Forest score : 0.34359533167020195\n"
     ]
    }
   ],
   "source": [
    "#Run models on test data\n",
    "print('Test data performance:\\n')\n",
    "print('Logistic Regressor score :',model_LR2.score(lowtest, y_test))\n",
    "print('SVM score :',model_SVM2.score(lowtest, y_test))\n",
    "print('Random Forest score :',model_RF2.score(lowtest, testLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "facf1638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data performance:\n",
      "\n",
      "Logistic Regressor score : 0.8326629636723488\n",
      "SVM score : 0.8296622613803231\n",
      "Random Forest score : 0.8758245994557877\n"
     ]
    }
   ],
   "source": [
    "#Run models on training data\n",
    "print('Training data performance:\\n')\n",
    "print('Logistic Regressor score :',model_LR2.score(lowtrain, y_train))\n",
    "print('SVM score :',model_SVM2.score(lowtrain, y_train))\n",
    "print('Random Forest score :',model_RF2.score(lowtrain, trainLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "72445d0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualize performance by Normalized confusion matrix\n",
    "import seaborn as sn\n",
    "numClasses = 3\n",
    "classes = ['EAP','HPL','MWS']\n",
    "\n",
    "conf = np.zeros([numClasses,numClasses])\n",
    "guesses = model_LR2.predict(lowtest)\n",
    "\n",
    "for s in range(lowtest.shape[0]):\n",
    "    real = classes.index(y_test[s])\n",
    "    guess = classes.index(guesses[s])\n",
    "    conf[real,guess] = conf[real,guess] + 1\n",
    " \n",
    "rowsums = np.sum(conf,1)\n",
    "rowsums = np.reshape(rowsums,[numClasses,1])\n",
    "rowsums = np.repeat(rowsums,numClasses, axis = 1)\n",
    "conf = conf / rowsums\n",
    "df_cm = pd.DataFrame(conf, index = [i for i in classes],\n",
    "                  columns = [i for i in classes])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9c146c",
   "metadata": {},
   "source": [
    "# NN and K-NN Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d74fc3",
   "metadata": {},
   "source": [
    "#### We use the sparse vectors here to fetch closest sentences to a (randomly chosen) query sentence. We use the nearest matches by Manhattan distance here. Manhattan distance has been shown to work better than Euclidean distance for comparing vectors that are histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0e1660d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query sentence: All attempts at logical inquiry resulted, indeed, in leaving me more sceptical than before.\n"
     ]
    }
   ],
   "source": [
    "queryNum = np.random.randint(trainData.shape[0]) # 4651\n",
    "query = X_train[queryNum]\n",
    "print('Query sentence:',query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6bbd56fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EAP:\tAll attempts at logical inquiry resulted, indeed, in leaving me more sceptical than before.\n",
      "EAP:\tRousseau Nouvelle Heloise.\n",
      "EAP:\tEmicant Trabes quos docos vocant.\n",
      "MWS:\tShakspeare's Sonnets.\n",
      "MWS:\tShakespeare's Sonnets.\n",
      "EAP:\tPundit is in ecstacies.\n",
      "EAP:\tAll efforts proved in vain.\n",
      "EAP:\tIndeed, every appearance warranted me in apprehending a Simoom.\n",
      "EAP:\t\"Indeed;\" repeated the vassal.\n",
      "EAP:\t\" Odenheimer, restaurateur.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances, manhattan_distances\n",
    "\n",
    "queryVector = trainData[queryNum,:]\n",
    "queryVector = queryVector.reshape(1, -1)\n",
    "dists1 = manhattan_distances(queryVector,trainData)\n",
    "sortedIdx = np.argsort(dists1)\n",
    "sortedIdx = np.squeeze(sortedIdx)\n",
    "\n",
    "for i in range(10):\n",
    "    sentence = X_train[sortedIdx[i]]      \n",
    "    label = y_train[sortedIdx[i]]\n",
    "    print(label +':\\t' + sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b31be3",
   "metadata": {},
   "source": [
    "#### As can be seen, the retrieved nearest neighbors only have a few words common with the query. Also, there words are often common words like \"is\" or \"the\". Now let's do the retrieval using the PCA dimensionality reduced vectors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2e66d97",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lowtrain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m queryVector \u001b[38;5;241m=\u001b[39m \u001b[43mlowtrain\u001b[49m[queryNum,:]\n\u001b[0;32m      2\u001b[0m queryVector \u001b[38;5;241m=\u001b[39m queryVector\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      3\u001b[0m dists2 \u001b[38;5;241m=\u001b[39m euclidean_distances(queryVector,lowtrain)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lowtrain' is not defined"
     ]
    }
   ],
   "source": [
    "queryVector = lowtrain[queryNum,:]\n",
    "queryVector = queryVector.reshape(1, -1)\n",
    "dists2 = euclidean_distances(queryVector,lowtrain)\n",
    "sortedIdx = np.argsort(dists2)\n",
    "sortedIdx = np.squeeze(sortedIdx)\n",
    "\n",
    "for i in range(10):\n",
    "    sentence = X_train[sortedIdx[i]]      \n",
    "    label = y_train[sortedIdx[i]]\n",
    "    print(label +':\\t' + sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4a1946f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 28350,\n",
       " 'of': 16739,\n",
       " 'and': 14252,\n",
       " 'to': 10224,\n",
       " 'i': 8650,\n",
       " 'a': 8515,\n",
       " 'in': 7564,\n",
       " 'was': 5296,\n",
       " 'that': 5101,\n",
       " 'my': 4305,\n",
       " 'it': 3873,\n",
       " 'he': 3477,\n",
       " 'had': 3475,\n",
       " 'with': 3470,\n",
       " 'his': 3282,\n",
       " 'as': 3053,\n",
       " 'for': 2808,\n",
       " 'which': 2693,\n",
       " 'but': 2679,\n",
       " 'not': 2624,\n",
       " 'at': 2596,\n",
       " 'me': 2351,\n",
       " 'by': 2298,\n",
       " 'from': 2292,\n",
       " 'is': 2217,\n",
       " 'this': 2086,\n",
       " 'on': 1995,\n",
       " 'be': 1930,\n",
       " 'her': 1827,\n",
       " 'were': 1739,\n",
       " 'have': 1693,\n",
       " 'all': 1601,\n",
       " 'you': 1549,\n",
       " 'an': 1479,\n",
       " 'we': 1418,\n",
       " 'or': 1396,\n",
       " 'no': 1349,\n",
       " 'one': 1291,\n",
       " 'so': 1266,\n",
       " 'him': 1215,\n",
       " 'when': 1200,\n",
       " 'upon': 1151,\n",
       " 'been': 1146,\n",
       " 'they': 1134,\n",
       " 'could': 1073,\n",
       " 'there': 1058,\n",
       " 'its': 1032,\n",
       " 'she': 1026,\n",
       " 'would': 993,\n",
       " 'more': 951,\n",
       " 'their': 929,\n",
       " 'now': 928,\n",
       " 'what': 868,\n",
       " 'some': 835,\n",
       " 'our': 833,\n",
       " 'are': 797,\n",
       " 'into': 769,\n",
       " 'than': 763,\n",
       " 'who': 742,\n",
       " 'will': 740,\n",
       " 'very': 735,\n",
       " 'if': 721,\n",
       " 'them': 711,\n",
       " 'only': 702,\n",
       " 'then': 668,\n",
       " 'up': 640,\n",
       " 'these': 620,\n",
       " 'about': 613,\n",
       " 'before': 605,\n",
       " 'any': 601,\n",
       " 'time': 586,\n",
       " 'man': 580,\n",
       " 'yet': 567,\n",
       " 'your': 565,\n",
       " 'said': 563,\n",
       " 'even': 561,\n",
       " 'did': 558,\n",
       " 'out': 555,\n",
       " 'might': 494,\n",
       " 'old': 490,\n",
       " 'after': 490,\n",
       " 'like': 486,\n",
       " 'must': 478,\n",
       " 'most': 474,\n",
       " 'life': 473,\n",
       " 'over': 472,\n",
       " 'first': 471,\n",
       " 'through': 467,\n",
       " 'us': 466,\n",
       " 'other': 460,\n",
       " '': 457,\n",
       " 'found': 449,\n",
       " 'made': 448,\n",
       " 'such': 444,\n",
       " 'should': 443,\n",
       " 'never': 442,\n",
       " 'night': 441,\n",
       " 'do': 436,\n",
       " 'seemed': 433,\n",
       " 'eyes': 432,\n",
       " 'every': 429,\n",
       " 'little': 422,\n",
       " 'long': 422,\n",
       " 'day': 418,\n",
       " 'those': 418,\n",
       " 'great': 416,\n",
       " 'has': 414,\n",
       " 'still': 411,\n",
       " 'myself': 409,\n",
       " 'while': 406,\n",
       " 'where': 405,\n",
       " 'saw': 396,\n",
       " 'own': 389,\n",
       " 'well': 384,\n",
       " 'many': 379,\n",
       " 'much': 375,\n",
       " 'down': 372,\n",
       " 'again': 370,\n",
       " 'came': 369,\n",
       " 'thought': 357,\n",
       " 'how': 351,\n",
       " 'two': 344,\n",
       " 'once': 342,\n",
       " 'may': 340,\n",
       " 'am': 339,\n",
       " 'being': 335,\n",
       " 'can': 334,\n",
       " 'here': 333,\n",
       " 'see': 328,\n",
       " 'thus': 325,\n",
       " 'whose': 321,\n",
       " 'ever': 321,\n",
       " 'say': 316,\n",
       " 'shall': 309,\n",
       " 'far': 303,\n",
       " 'death': 298,\n",
       " 'thing': 296,\n",
       " 'mind': 296,\n",
       " 'however': 293,\n",
       " 'too': 292,\n",
       " 'men': 290,\n",
       " 'things': 288,\n",
       " 'without': 288,\n",
       " 'heard': 283,\n",
       " 'house': 281,\n",
       " 'left': 279,\n",
       " 'years': 277,\n",
       " 'felt': 276,\n",
       " 'last': 274,\n",
       " 'heart': 270,\n",
       " 'place': 267,\n",
       " 'himself': 267,\n",
       " 'know': 265,\n",
       " 'love': 259,\n",
       " 'few': 258,\n",
       " 'come': 254,\n",
       " 'though': 253,\n",
       " 'indeed': 252,\n",
       " 'light': 248,\n",
       " 'world': 247,\n",
       " 'head': 244,\n",
       " 'back': 243,\n",
       " 'nothing': 242,\n",
       " 'room': 242,\n",
       " 'let': 241,\n",
       " 'became': 240,\n",
       " 'way': 240,\n",
       " 'whole': 240,\n",
       " 'earth': 239,\n",
       " 'nor': 237,\n",
       " 'each': 236,\n",
       " 'hand': 236,\n",
       " 'among': 235,\n",
       " 'having': 230,\n",
       " 'words': 229,\n",
       " 'within': 229,\n",
       " 'away': 229,\n",
       " 'nature': 227,\n",
       " 'knew': 226,\n",
       " 'same': 224,\n",
       " 'length': 223,\n",
       " 'door': 221,\n",
       " 'three': 221,\n",
       " 'voice': 221,\n",
       " 'good': 220,\n",
       " 'make': 219,\n",
       " 'strange': 219,\n",
       " 'friend': 218,\n",
       " 'seen': 216,\n",
       " 'human': 215,\n",
       " 'under': 215,\n",
       " 'soon': 213,\n",
       " 'part': 212,\n",
       " 'during': 212,\n",
       " 'half': 211,\n",
       " 'moment': 210,\n",
       " 'beyond': 209,\n",
       " 'although': 209,\n",
       " 'new': 206,\n",
       " 'alone': 206,\n",
       " 'raymond': 204,\n",
       " 'off': 203,\n",
       " 'since': 202,\n",
       " 'less': 201,\n",
       " 'gave': 197,\n",
       " 'sea': 197,\n",
       " 'air': 194,\n",
       " 'just': 194,\n",
       " 'fear': 191,\n",
       " 'looked': 191,\n",
       " 'find': 190,\n",
       " 'father': 187,\n",
       " 'young': 185,\n",
       " 'another': 185,\n",
       " 'near': 185,\n",
       " 'almost': 185,\n",
       " 'days': 184,\n",
       " 'soul': 184,\n",
       " 'full': 183,\n",
       " 'city': 181,\n",
       " 'end': 180,\n",
       " 'dark': 180,\n",
       " 'body': 179,\n",
       " 'certain': 178,\n",
       " 'small': 177,\n",
       " 'took': 176,\n",
       " 'why': 176,\n",
       " 'passed': 175,\n",
       " 'around': 175,\n",
       " 'above': 171,\n",
       " 'told': 170,\n",
       " 'course': 170,\n",
       " 'appeared': 169,\n",
       " 'dead': 169,\n",
       " 'mr': 168,\n",
       " 'went': 167,\n",
       " 'itself': 167,\n",
       " 'face': 166,\n",
       " 'take': 166,\n",
       " 'something': 166,\n",
       " 'horror': 165,\n",
       " 'spirit': 164,\n",
       " 'lay': 164,\n",
       " 'whom': 163,\n",
       " 'point': 162,\n",
       " 'high': 160,\n",
       " 'perhaps': 160,\n",
       " 'idea': 159,\n",
       " 'go': 159,\n",
       " 'began': 158,\n",
       " 'think': 158,\n",
       " 'between': 157,\n",
       " 'matter': 156,\n",
       " 'also': 156,\n",
       " 'least': 155,\n",
       " 'form': 155,\n",
       " 'open': 154,\n",
       " 'lost': 153,\n",
       " 'name': 152,\n",
       " 'hope': 152,\n",
       " 'black': 152,\n",
       " 'water': 151,\n",
       " 'until': 150,\n",
       " 'kind': 150,\n",
       " 'tell': 150,\n",
       " 'often': 146,\n",
       " 'manner': 146,\n",
       " 'deep': 145,\n",
       " 'right': 144,\n",
       " 'hours': 143,\n",
       " 'look': 143,\n",
       " 'side': 142,\n",
       " 'known': 142,\n",
       " 'home': 142,\n",
       " 'power': 141,\n",
       " 'rather': 141,\n",
       " 'cannot': 141,\n",
       " 'moon': 140,\n",
       " 'turned': 140,\n",
       " 'street': 140,\n",
       " 'feel': 139,\n",
       " 'brought': 139,\n",
       " 'o': 138,\n",
       " 'fell': 137,\n",
       " 'scene': 137,\n",
       " 'put': 137,\n",
       " 'present': 137,\n",
       " 'against': 136,\n",
       " 'feet': 136,\n",
       " 'sound': 136,\n",
       " 'always': 136,\n",
       " 'hour': 135,\n",
       " 'object': 135,\n",
       " 'called': 134,\n",
       " 'means': 133,\n",
       " 'person': 133,\n",
       " 'towards': 133,\n",
       " 'eye': 133,\n",
       " 'because': 133,\n",
       " 'taken': 133,\n",
       " 'people': 132,\n",
       " 'nearly': 132,\n",
       " 'become': 131,\n",
       " 'de': 131,\n",
       " 'spoke': 131,\n",
       " 'morning': 131,\n",
       " 'sometimes': 130,\n",
       " 'return': 130,\n",
       " 'large': 130,\n",
       " 'both': 128,\n",
       " 'doubt': 128,\n",
       " 'hands': 127,\n",
       " 'ancient': 127,\n",
       " 'sun': 127,\n",
       " 'country': 126,\n",
       " 'better': 126,\n",
       " 'thousand': 126,\n",
       " 'general': 125,\n",
       " 'longer': 125,\n",
       " 'dream': 125,\n",
       " 'true': 125,\n",
       " 'sight': 124,\n",
       " 'done': 124,\n",
       " 'truth': 123,\n",
       " 'fact': 123,\n",
       " 'set': 122,\n",
       " 'state': 122,\n",
       " 'give': 122,\n",
       " 'several': 122,\n",
       " 'white': 122,\n",
       " 'entered': 120,\n",
       " 'believe': 120,\n",
       " 'perdita': 120,\n",
       " 'speak': 119,\n",
       " 'stood': 119,\n",
       " 'wild': 119,\n",
       " 'town': 119,\n",
       " 'others': 119,\n",
       " 'suddenly': 118,\n",
       " 'dreams': 117,\n",
       " 'second': 117,\n",
       " 'grew': 116,\n",
       " 'continued': 116,\n",
       " 'terrible': 116,\n",
       " 'quite': 116,\n",
       " 'beauty': 115,\n",
       " 'remained': 115,\n",
       " 'appearance': 114,\n",
       " 'possible': 114,\n",
       " 'word': 114,\n",
       " 'work': 114,\n",
       " 'sense': 113,\n",
       " 'dear': 113,\n",
       " 'wind': 113,\n",
       " 'reason': 113,\n",
       " 'sleep': 112,\n",
       " 'change': 112,\n",
       " 'beneath': 112,\n",
       " 'family': 112,\n",
       " 'times': 112,\n",
       " 'case': 111,\n",
       " 'god': 110,\n",
       " 'ground': 110,\n",
       " 'read': 110,\n",
       " 'poor': 109,\n",
       " 'period': 109,\n",
       " 'trees': 109,\n",
       " 'despair': 107,\n",
       " 'past': 107,\n",
       " 'till': 107,\n",
       " 'stone': 107,\n",
       " 'west': 106,\n",
       " 'floor': 106,\n",
       " 'view': 105,\n",
       " 'character': 105,\n",
       " 'given': 105,\n",
       " 'toward': 105,\n",
       " 'looking': 105,\n",
       " 'get': 104,\n",
       " 'vast': 104,\n",
       " 'already': 103,\n",
       " 'question': 103,\n",
       " 'close': 103,\n",
       " 'themselves': 102,\n",
       " 'attention': 102,\n",
       " 'adrian': 102,\n",
       " 'therefore': 101,\n",
       " 'land': 101,\n",
       " 'together': 101,\n",
       " 'next': 101,\n",
       " 'account': 100,\n",
       " 'five': 99,\n",
       " 'oh': 99,\n",
       " 'tears': 99,\n",
       " 'happy': 99,\n",
       " 'low': 99,\n",
       " 'happiness': 98,\n",
       " 'replied': 98,\n",
       " 'thoughts': 98,\n",
       " 'returned': 97,\n",
       " 'none': 97,\n",
       " 'leave': 96,\n",
       " 'best': 96,\n",
       " 'sat': 96,\n",
       " 'died': 96,\n",
       " 'mere': 96,\n",
       " 'hideous': 95,\n",
       " 'either': 95,\n",
       " 'rest': 95,\n",
       " 'interest': 95,\n",
       " 'countenance': 95,\n",
       " 'immediately': 95,\n",
       " 'gentle': 94,\n",
       " 'evil': 94,\n",
       " 'cold': 94,\n",
       " 'natural': 94,\n",
       " 'sure': 94,\n",
       " 'walls': 94,\n",
       " 'latter': 93,\n",
       " 'behind': 93,\n",
       " 'space': 93,\n",
       " 'blood': 93,\n",
       " 'child': 93,\n",
       " 'observed': 92,\n",
       " 'led': 92,\n",
       " 'enough': 92,\n",
       " 'unknown': 92,\n",
       " 'chamber': 92,\n",
       " 'window': 92,\n",
       " 'sky': 92,\n",
       " 'age': 92,\n",
       " 'discovered': 91,\n",
       " 'england': 91,\n",
       " 'children': 91,\n",
       " 'filled': 90,\n",
       " 'evening': 90,\n",
       " 'remember': 90,\n",
       " 'four': 89,\n",
       " 'memory': 89,\n",
       " 'friends': 89,\n",
       " 'mother': 89,\n",
       " 'wall': 89,\n",
       " 'existence': 88,\n",
       " 'gone': 88,\n",
       " 'knowledge': 88,\n",
       " 'idris': 88,\n",
       " 'green': 88,\n",
       " 'expression': 88,\n",
       " 'living': 87,\n",
       " 'formed': 87,\n",
       " 'below': 87,\n",
       " 'short': 87,\n",
       " 'feeling': 87,\n",
       " 'portion': 86,\n",
       " 'arms': 86,\n",
       " 'forth': 86,\n",
       " 'fire': 86,\n",
       " 'wonder': 86,\n",
       " 'hear': 85,\n",
       " 'misery': 85,\n",
       " 'degree': 85,\n",
       " 'wish': 85,\n",
       " 'self': 85,\n",
       " 'call': 85,\n",
       " 'joy': 85,\n",
       " 'neither': 85,\n",
       " 'feelings': 84,\n",
       " 'river': 84,\n",
       " 'care': 84,\n",
       " 'merely': 84,\n",
       " 'held': 84,\n",
       " 'lips': 84,\n",
       " 'sought': 83,\n",
       " 'spot': 83,\n",
       " 'secret': 83,\n",
       " 'impossible': 83,\n",
       " 'corpse': 83,\n",
       " 'difficulty': 83,\n",
       " 'subject': 83,\n",
       " 'die': 83,\n",
       " 'herself': 82,\n",
       " 'late': 82,\n",
       " 'sir': 82,\n",
       " 'peculiar': 81,\n",
       " 'fellow': 81,\n",
       " 'use': 81,\n",
       " 'windows': 81,\n",
       " 'greater': 81,\n",
       " 'cause': 80,\n",
       " 'distance': 80,\n",
       " 'heaven': 80,\n",
       " 'bed': 80,\n",
       " 'silence': 80,\n",
       " 'early': 79,\n",
       " 'followed': 79,\n",
       " 'reached': 79,\n",
       " 'really': 78,\n",
       " 'grave': 78,\n",
       " 'loved': 78,\n",
       " 'mad': 78,\n",
       " 'possessed': 78,\n",
       " 'imagination': 78,\n",
       " 'altogether': 78,\n",
       " 'year': 78,\n",
       " 'usual': 78,\n",
       " 'necessary': 78,\n",
       " 'purpose': 78,\n",
       " 'box': 77,\n",
       " 'terror': 77,\n",
       " 'scarcely': 77,\n",
       " 'shadow': 77,\n",
       " 'mine': 77,\n",
       " 'along': 77,\n",
       " 'months': 77,\n",
       " 'arm': 76,\n",
       " 'lady': 76,\n",
       " 'steps': 76,\n",
       " 'sweet': 76,\n",
       " 'especially': 76,\n",
       " 'somewhat': 76,\n",
       " 'ill': 75,\n",
       " 'table': 75,\n",
       " 'placed': 75,\n",
       " 'thou': 75,\n",
       " 'hundred': 75,\n",
       " 'fully': 74,\n",
       " 'grief': 74,\n",
       " 'youth': 74,\n",
       " 'common': 74,\n",
       " 'beautiful': 74,\n",
       " 'save': 74,\n",
       " 'line': 74,\n",
       " 'hills': 74,\n",
       " 'live': 73,\n",
       " 'mountain': 73,\n",
       " 'houses': 73,\n",
       " 'met': 73,\n",
       " 'dr': 73,\n",
       " 'beheld': 73,\n",
       " 'heavy': 73,\n",
       " 'twenty': 72,\n",
       " 'fancy': 72,\n",
       " 'circumstances': 72,\n",
       " 'coming': 72,\n",
       " 'visible': 72,\n",
       " 'cast': 72,\n",
       " 'arose': 72,\n",
       " 'former': 72,\n",
       " 'does': 72,\n",
       " 'resolved': 72,\n",
       " 'kept': 71,\n",
       " 'whether': 71,\n",
       " 'order': 71,\n",
       " 'six': 71,\n",
       " 'proceeded': 71,\n",
       " 'affection': 71,\n",
       " 'presence': 71,\n",
       " 'ye': 71,\n",
       " 'pleasure': 71,\n",
       " 'entirely': 71,\n",
       " 'delight': 70,\n",
       " 'wide': 70,\n",
       " 'london': 70,\n",
       " 'girl': 70,\n",
       " 'plague': 70,\n",
       " 'received': 70,\n",
       " 'distant': 70,\n",
       " 'rose': 70,\n",
       " 'turn': 70,\n",
       " 'letter': 69,\n",
       " 'books': 69,\n",
       " 'lived': 69,\n",
       " 'round': 69,\n",
       " 'minutes': 69,\n",
       " 'opened': 68,\n",
       " 'asked': 68,\n",
       " 'calm': 68,\n",
       " 'caused': 68,\n",
       " 'ten': 68,\n",
       " 'hold': 68,\n",
       " 'finally': 68,\n",
       " 'odd': 68,\n",
       " 'boat': 68,\n",
       " 'thrown': 68,\n",
       " 'hair': 67,\n",
       " 'lovely': 67,\n",
       " 'horrible': 67,\n",
       " 'instant': 67,\n",
       " 'darkness': 67,\n",
       " 'sister': 67,\n",
       " 'hill': 67,\n",
       " 'force': 67,\n",
       " 'motion': 67,\n",
       " 'public': 67,\n",
       " 'stars': 67,\n",
       " 'understand': 66,\n",
       " 'threw': 66,\n",
       " 'tried': 66,\n",
       " 'balloon': 66,\n",
       " 'anything': 66,\n",
       " 'lord': 66,\n",
       " 'wife': 66,\n",
       " 'various': 66,\n",
       " 'events': 66,\n",
       " 'north': 66,\n",
       " 'ears': 66,\n",
       " 'alas': 66,\n",
       " 'going': 66,\n",
       " 'silent': 66,\n",
       " 'business': 66,\n",
       " 'paper': 66,\n",
       " 'broken': 66,\n",
       " 'singular': 65,\n",
       " 'entire': 65,\n",
       " 'escape': 65,\n",
       " 'sorrow': 65,\n",
       " 'ordinary': 65,\n",
       " 'across': 65,\n",
       " 'strength': 65,\n",
       " 'apparently': 65,\n",
       " 'figure': 65,\n",
       " 'streets': 65,\n",
       " 'position': 65,\n",
       " 'excited': 65,\n",
       " 'says': 64,\n",
       " 'apparent': 64,\n",
       " 'real': 64,\n",
       " 'forgotten': 64,\n",
       " 'effect': 64,\n",
       " 'pain': 64,\n",
       " 'companion': 64,\n",
       " 'beloved': 64,\n",
       " 'slight': 64,\n",
       " 'society': 63,\n",
       " 'hopes': 63,\n",
       " 'mean': 63,\n",
       " 'easily': 63,\n",
       " 'single': 63,\n",
       " 'narrow': 63,\n",
       " 'arrived': 63,\n",
       " 'closed': 63,\n",
       " 'future': 63,\n",
       " 'influence': 63,\n",
       " 'book': 63,\n",
       " 'atmosphere': 63,\n",
       " 'surface': 63,\n",
       " 'road': 63,\n",
       " 'else': 62,\n",
       " 'woman': 62,\n",
       " 'cut': 62,\n",
       " 'struck': 62,\n",
       " 'sounds': 62,\n",
       " 'red': 62,\n",
       " 'visit': 62,\n",
       " 'fallen': 62,\n",
       " 'clear': 62,\n",
       " 'spent': 62,\n",
       " 'native': 62,\n",
       " 'uncle': 62,\n",
       " 'considered': 61,\n",
       " 'later': 61,\n",
       " 'party': 61,\n",
       " 'simple': 61,\n",
       " 'regard': 61,\n",
       " 'cottage': 61,\n",
       " 'east': 61,\n",
       " 'certainly': 61,\n",
       " 'direction': 61,\n",
       " 'born': 61,\n",
       " 'art': 60,\n",
       " 'windsor': 60,\n",
       " 'sufficiently': 60,\n",
       " 'top': 60,\n",
       " 'wished': 60,\n",
       " 'objects': 60,\n",
       " 'dont': 60,\n",
       " 'english': 60,\n",
       " 'yourself': 60,\n",
       " 'ship': 60,\n",
       " 'sufficient': 60,\n",
       " 'mentioned': 60,\n",
       " 'pale': 60,\n",
       " 'design': 60,\n",
       " 'deserted': 60,\n",
       " 'ago': 60,\n",
       " 'mountains': 59,\n",
       " 'health': 59,\n",
       " 'yes': 59,\n",
       " 'story': 59,\n",
       " 'miserable': 59,\n",
       " 'm': 59,\n",
       " 'changed': 59,\n",
       " 'outside': 59,\n",
       " 'making': 59,\n",
       " 'south': 59,\n",
       " 'remain': 59,\n",
       " 'madness': 58,\n",
       " 'bear': 58,\n",
       " 'keep': 58,\n",
       " 'shore': 58,\n",
       " 'action': 58,\n",
       " 'frame': 58,\n",
       " 'faint': 58,\n",
       " 'passion': 58,\n",
       " 'cried': 58,\n",
       " 'music': 58,\n",
       " 'vain': 58,\n",
       " 'valley': 58,\n",
       " 'fresh': 58,\n",
       " 'tale': 58,\n",
       " 'desire': 58,\n",
       " 'madame': 57,\n",
       " 'covered': 57,\n",
       " 'passage': 57,\n",
       " 'ocean': 57,\n",
       " 'bore': 57,\n",
       " 'alive': 57,\n",
       " 'appear': 57,\n",
       " 'creature': 57,\n",
       " 'gold': 57,\n",
       " 'extreme': 57,\n",
       " 'tomb': 57,\n",
       " 'fate': 57,\n",
       " 'company': 57,\n",
       " 'danger': 57,\n",
       " 'tree': 57,\n",
       " 'perceived': 57,\n",
       " 'number': 56,\n",
       " 'castle': 56,\n",
       " 'extent': 56,\n",
       " 'boy': 56,\n",
       " 'bring': 56,\n",
       " 'utterly': 56,\n",
       " 'whilst': 56,\n",
       " 'able': 56,\n",
       " 'condition': 56,\n",
       " 'blue': 56,\n",
       " 'thy': 56,\n",
       " 'free': 56,\n",
       " 'result': 56,\n",
       " 'expected': 56,\n",
       " 'gentleman': 56,\n",
       " 'waters': 56,\n",
       " 'step': 55,\n",
       " 'sole': 55,\n",
       " 'want': 55,\n",
       " 'perceive': 55,\n",
       " 'vague': 55,\n",
       " 'courage': 55,\n",
       " 'height': 55,\n",
       " 'immediate': 55,\n",
       " 'hung': 55,\n",
       " 'gods': 54,\n",
       " 'foot': 54,\n",
       " 'spring': 54,\n",
       " 'third': 54,\n",
       " 'mouth': 54,\n",
       " 'besides': 54,\n",
       " 'drew': 54,\n",
       " 'ice': 54,\n",
       " 'seized': 54,\n",
       " 'rain': 54,\n",
       " 'taking': 54,\n",
       " 'st': 54,\n",
       " 'elizabeth': 54,\n",
       " 'machine': 53,\n",
       " 'prepared': 53,\n",
       " 'bottom': 53,\n",
       " 'help': 53,\n",
       " 'evidently': 53,\n",
       " 'path': 53,\n",
       " 'talk': 53,\n",
       " 'wood': 53,\n",
       " 'perfect': 52,\n",
       " 'absence': 52,\n",
       " 'rise': 52,\n",
       " 'son': 52,\n",
       " 'supposed': 52,\n",
       " 'beings': 52,\n",
       " 'got': 52,\n",
       " 'smile': 52,\n",
       " 'miles': 52,\n",
       " 'reality': 52,\n",
       " 'remote': 52,\n",
       " 'queer': 52,\n",
       " 'winter': 52,\n",
       " 'senses': 52,\n",
       " 'seek': 52,\n",
       " 'huge': 52,\n",
       " 'main': 52,\n",
       " 'pass': 51,\n",
       " 'forms': 51,\n",
       " 'plain': 51,\n",
       " 'gilman': 51,\n",
       " 'similar': 51,\n",
       " 'fall': 51,\n",
       " 'greatest': 51,\n",
       " 'sort': 51,\n",
       " 'village': 51,\n",
       " 'different': 51,\n",
       " 'conversation': 51,\n",
       " 'succeeded': 51,\n",
       " 'slowly': 51,\n",
       " 'brain': 51,\n",
       " 'hardly': 50,\n",
       " 'exceedingly': 50,\n",
       " 'discovery': 50,\n",
       " 'dared': 50,\n",
       " 'forest': 50,\n",
       " 'apartment': 50,\n",
       " 'attempt': 50,\n",
       " 'reach': 50,\n",
       " 'moved': 50,\n",
       " 'tall': 50,\n",
       " 'need': 50,\n",
       " 'marble': 50,\n",
       " 'forever': 49,\n",
       " 'persons': 49,\n",
       " 'learned': 49,\n",
       " 'except': 49,\n",
       " 'respect': 49,\n",
       " 'progress': 49,\n",
       " 'curiosity': 49,\n",
       " 'enter': 49,\n",
       " 'creatures': 49,\n",
       " 'flowers': 49,\n",
       " 'solitude': 49,\n",
       " 'walked': 49,\n",
       " 'brief': 49,\n",
       " 'fears': 49,\n",
       " 'carried': 49,\n",
       " 'suffered': 49,\n",
       " 'watch': 49,\n",
       " 'places': 49,\n",
       " 'ideas': 48,\n",
       " 'determined': 48,\n",
       " 'leaving': 48,\n",
       " 'original': 48,\n",
       " 'listened': 48,\n",
       " 'melancholy': 48,\n",
       " 'glass': 48,\n",
       " 'task': 48,\n",
       " 'remarkable': 48,\n",
       " 'added': 48,\n",
       " 'believed': 48,\n",
       " 'island': 48,\n",
       " 'car': 48,\n",
       " 'breath': 48,\n",
       " 'rendered': 48,\n",
       " 'shewed': 48,\n",
       " 'genius': 47,\n",
       " 'following': 47,\n",
       " 'hard': 47,\n",
       " 'answer': 47,\n",
       " 'fair': 47,\n",
       " 'promise': 47,\n",
       " 'vision': 47,\n",
       " 'seems': 47,\n",
       " 'talked': 47,\n",
       " 'whatever': 47,\n",
       " 'used': 47,\n",
       " 'move': 47,\n",
       " 'nose': 47,\n",
       " 'bent': 47,\n",
       " 'evidence': 47,\n",
       " 'features': 47,\n",
       " 'intense': 47,\n",
       " 'curious': 47,\n",
       " 'opinion': 47,\n",
       " 'imagine': 47,\n",
       " 'sympathy': 47,\n",
       " 'golden': 47,\n",
       " 'relief': 47,\n",
       " 'meet': 47,\n",
       " 'mystery': 47,\n",
       " 'occurred': 47,\n",
       " 'image': 47,\n",
       " 'strong': 47,\n",
       " 'peace': 47,\n",
       " 'approached': 46,\n",
       " 'burst': 46,\n",
       " 'situation': 46,\n",
       " 'building': 46,\n",
       " 'system': 46,\n",
       " 'destroyed': 46,\n",
       " 'rich': 46,\n",
       " 'dare': 46,\n",
       " 'sent': 46,\n",
       " 'language': 46,\n",
       " 'circumstance': 46,\n",
       " 'key': 46,\n",
       " 'journey': 46,\n",
       " 'occupied': 46,\n",
       " 'afternoon': 46,\n",
       " 'heavens': 46,\n",
       " 'star': 46,\n",
       " 'noble': 46,\n",
       " 'innsmouth': 46,\n",
       " 'week': 46,\n",
       " 'thee': 46,\n",
       " 'evident': 46,\n",
       " 'horizon': 46,\n",
       " 'powers': 46,\n",
       " 'fearful': 46,\n",
       " 'animal': 46,\n",
       " 'feared': 46,\n",
       " 'arkham': 46,\n",
       " 'sudden': 45,\n",
       " 'study': 45,\n",
       " 'seem': 45,\n",
       " 'frightful': 45,\n",
       " 'fine': 45,\n",
       " 'agony': 45,\n",
       " 'temple': 45,\n",
       " 'voices': 45,\n",
       " 'individual': 45,\n",
       " 'follow': 45,\n",
       " 'act': 45,\n",
       " 'remembered': 45,\n",
       " 'midnight': 45,\n",
       " 'grey': 45,\n",
       " 'eight': 45,\n",
       " 'started': 45,\n",
       " 'ones': 45,\n",
       " 'concerning': 45,\n",
       " 'watched': 45,\n",
       " 'utter': 45,\n",
       " 'gazed': 45,\n",
       " 'rock': 45,\n",
       " 'describe': 45,\n",
       " 'farther': 44,\n",
       " 'spread': 44,\n",
       " 'suppose': 44,\n",
       " 'degrees': 44,\n",
       " 'physical': 44,\n",
       " 'mighty': 44,\n",
       " 'amidst': 44,\n",
       " 'clouds': 44,\n",
       " 'spirits': 44,\n",
       " 'marked': 44,\n",
       " 'soft': 44,\n",
       " 'instead': 44,\n",
       " 'ceased': 44,\n",
       " 'fever': 44,\n",
       " 'slept': 44,\n",
       " 'success': 44,\n",
       " 'ran': 44,\n",
       " 'descent': 44,\n",
       " 'corner': 43,\n",
       " 'moments': 43,\n",
       " 'dupin': 43,\n",
       " 'king': 43,\n",
       " 'afterward': 43,\n",
       " 'fathers': 43,\n",
       " 'science': 43,\n",
       " 'reflection': 43,\n",
       " 'storm': 43,\n",
       " 'glance': 43,\n",
       " 'crowd': 43,\n",
       " 'region': 43,\n",
       " 'summer': 43,\n",
       " 'quiet': 43,\n",
       " 'increased': 43,\n",
       " 'giving': 43,\n",
       " 'trace': 43,\n",
       " 'feeble': 42,\n",
       " 'satisfied': 42,\n",
       " 'permitted': 42,\n",
       " 'otherwise': 42,\n",
       " 'departed': 42,\n",
       " 'professor': 42,\n",
       " 'woods': 42,\n",
       " 'quickly': 42,\n",
       " 'distinct': 42,\n",
       " 'mental': 42,\n",
       " 'hidden': 42,\n",
       " 'bodies': 42,\n",
       " 'happened': 42,\n",
       " 'meantime': 42,\n",
       " 'visited': 42,\n",
       " 'effort': 42,\n",
       " 'dying': 42,\n",
       " 'proper': 42,\n",
       " 'unusual': 42,\n",
       " 'failed': 42,\n",
       " 'beside': 42,\n",
       " 'paused': 41,\n",
       " 'possession': 41,\n",
       " 'bitter': 41,\n",
       " 'sad': 41,\n",
       " 'aware': 41,\n",
       " 'fled': 41,\n",
       " 'inhabitants': 41,\n",
       " 'limbs': 41,\n",
       " 'chance': 41,\n",
       " 'size': 41,\n",
       " 'reply': 41,\n",
       " 'laws': 41,\n",
       " 'material': 41,\n",
       " 'grown': 41,\n",
       " ...}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_vocab"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
