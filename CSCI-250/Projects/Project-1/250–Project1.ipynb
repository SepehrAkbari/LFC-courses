{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Logistics**\n",
    "\n",
    "1. **Team**: \n",
    "\n",
    "    - **Sepehr Akbari**\n",
    "\n",
    "    - **Carson Pagel**\n",
    "\n",
    "2. **Assignment**:\n",
    "\n",
    "    - CSCI 250: Programming for Data Applications\n",
    "\n",
    "        - Project 1\n",
    "\n",
    "3. **Data**:\n",
    "\n",
    "    - Name: *Ecommerce Customer Churn Analysis and Prediction*\n",
    "    \n",
    "    - Source: [Kaggle](https://www.kaggle.com/datasets/ankitverma2010/ecommerce-customer-churn-analysis-and-prediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Customer Churn Prediction**\n",
    "\n",
    "**Objective:**\n",
    "\n",
    "Customer churn prediction is a common problem in the telecommunication industry. It is important for companies to identify customers who are likely to churn in order to take preventive actions to retain them. Furthermore, it is beneficiary for companies to understand the factors that lead to customer churn. In this project, we will use machine learning models to predict customer churn based on a dataset from a telecommunication company.\n",
    "\n",
    "**Table of Content:**\n",
    "\n",
    "1. [Setup](#setup)\n",
    "\n",
    "2. [Exploratory Data Analysis (EDA)](#exploratory-data-analysis-eda)\n",
    "\n",
    "3. [Data Encoding & Imputation](#data-encoding--imputation)\n",
    "\n",
    "4. [Correlation Analysis](#correlation-analysis)\n",
    "\n",
    "5. [Handling Imbalanced Data & Scaling](#handling-imbalanced-data--scaling)\n",
    "\n",
    "6. [Regression Models](#regression-models)\n",
    "\n",
    "    - [Linear Regression](#linear-regression)\n",
    "\n",
    "    - [Polynomial Regression](#polynomial-regression)\n",
    "\n",
    "    - [Logistic Regression](#logistic-regression)\n",
    "\n",
    "7. [K-Nearest Neighbors (kNN) Models](#k-nearest-neighbors-knn-models)\n",
    "\n",
    "    - [Euclidean Distance](#euclidean-distance)\n",
    "\n",
    "    - [Manhattan Distance](#manhattan-distance)\n",
    "\n",
    "8. [Support Vector Machine (SVM) Models](#support-vector-machine-svm-model)\n",
    "\n",
    "    - [Linear Kernel](#linear-svm)\n",
    "\n",
    "    - [Non-Linear Kernel](#non-linear-svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **importing libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingClassifier\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, mean_squared_error, precision_score, r2_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the random state the models will use, for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = 250"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Importing the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('data.xlsx', sheet_name='E Comm')\n",
    "desc = pd.read_excel('data.xlsx', sheet_name='Data Dict', header=1, usecols=[1,2,3]).drop(columns=\"Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Description of the data columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Peaking the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we want to explore and understand the data. We will look at the distribution of the target variable, the distribution of the features, and the relationship between the target variable and the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Analyzing the type of data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like all the data are in appropriate format, no need to change the data type.\n",
    "\n",
    "2. **Dropping `customerID` column**\n",
    "\n",
    "We'll drop the `customerID` column as it is not useful for our analysis, nor is a feature for churn prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=\"CustomerID\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Lets get the count of some interesting variables, to get an idea of what the data represents.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,40))\n",
    "n = 1\n",
    "colors = sns.color_palette(\"plasma\", len(df.columns))\n",
    "for i, col in enumerate(df.columns):\n",
    "    plt.subplot(10,2,n)\n",
    "    sns.histplot(df, x=col, bins=25, color=colors[i])\n",
    "    plt.title(f\"Distribution of {col}\")\n",
    "    plt.xlabel(\"\")\n",
    "    plt.ylabel(\"\")\n",
    "    plt.grid(True)\n",
    "    n += 1\n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are a couple of important things these visualizations tell us:\n",
    "\n",
    "- The data shows that the majority of customers do not churn, with only a smaller fraction leaving.\n",
    "\n",
    "- There are fewer senior citizens than non-seniors, suggesting age might be a smaller but potentially significant factor.\n",
    "\n",
    "- Tenure varies widely, with many customers having short tenure, which could indicate higher churn risk.\n",
    "\n",
    "- Monthly charges are skewed, suggesting that a smaller subset of customers pay much higher fees.\n",
    "\n",
    "- Total charges are also right-skewed, typically increasing with customer tenure.\n",
    "\n",
    "- Certain internet service types and add-ons dominate, possibly influencing churn based on specific service preferences.\n",
    "\n",
    "- Payment methods vary, with certain methods (like month-to-month) often linked to higher churn.\n",
    "\n",
    "- Contract type, additional services, and senior citizen status stand out as potential predictors of churn.\n",
    "\n",
    "- Outliers and missing values in total charges and other features may need special handling before modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Encoding & Imputation\n",
    "\n",
    "1. **Checking for missing values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Count of missing values in each column:\\n\\n{df.isnull().sum()}\\n---')\n",
    "print(f'Total missing: {df.isnull().sum().sum()}')\n",
    "print(f'Total rows missing (at least one): {df[df.isnull().any(axis=1)].shape[0]}')\n",
    "print(f'Percentage of missing values in db: {df.isnull().sum().sum() / df.shape[0] * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that no one row has more than one missing value, which is actually a bad thing, as it implies if we drop all rows with missing values, we will lose aout 33% of our data.\n",
    "\n",
    "So we need to impute the missing values. I'll use `simpleImputer` for numeric columns and `iterativeImputer` with a RandomForestRegressor for categorical columns.\n",
    "\n",
    "2. **Imputing missing values for numeric columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerics = df.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "df[numerics] = SimpleImputer(strategy='mean').fit_transform(df[numerics])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Encoding categorical columns (One-Hot Encoding)**\n",
    "\n",
    "This allows us to convert categorical columns into numerical columns, which is necessary for most machine learning models, especially regressions which we'll be using. We can use `drop_first=True` to avoid multicollinearity which will help our model to generalize better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals = df.select_dtypes(include=['object']).columns.tolist()\n",
    "df = pd.get_dummies(df, columns=categoricals, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Imputing missing values for categorical columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_imputer = IterativeImputer(estimator=RandomForestRegressor(random_state=rs), max_iter=10)\n",
    "df = pd.DataFrame(rf_imputer.fit_transform(df), columns=df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **Displaying the imputed and encoded data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have imputed and encoded the data, we can look at the correlation between the features and the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_corr = df.corr()[\"Churn\"].sort_values(ascending=False)\n",
    "churn_corr = churn_corr.drop(\"Churn\")\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(x=churn_corr.values, y=churn_corr.index, palette=\"RdBu\")\n",
    "\n",
    "plt.xlabel(\"Correlation with Churn\")\n",
    "plt.ylabel(\"\")\n",
    "plt.title(\"Feature Correlations with Churn\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This corrolation chart indicates:\n",
    "\n",
    "- **Complain** has the highest positive correlation with churn, indicating that customers who lodge complaints are more likely to leave.\n",
    "\n",
    "- **MaritalStatus_Single** also correlates positively with churn, suggesting single customers may have a higher tendency to churn.\n",
    "\n",
    "- **PreferredOrderCat_Mobile** Phone shows a moderate positive correlation, implying those who primarily order mobile phones could be more prone to churn.\n",
    "\n",
    "- **NumberOfDeviceRegistered** and **SatisfactionScore** both have moderate positive correlations, hinting that device usage and satisfaction levels relate to churn risk.\n",
    "\n",
    "- **MaritalStatus_Married**, **CashbackAmount**, **DaySinceLastOrder**, and **Tenure** all show negative correlations, meaning married customers, those receiving higher cashback, and longer-term or more recently active customers are less likely to churn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Specifying the target variable (`y`) and the features (`X`)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"Churn\"])\n",
    "y = df[\"Churn\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Splitting the data into training and testing sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=rs, stratify=y)\n",
    "\n",
    "print(f\"Training set's shape: {X_train.shape}\")\n",
    "print(f\"Testing set's shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Imbalanced Data & Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Evaluating the imbalance of `Churn`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,4))\n",
    "\n",
    "churn_percentages = df[\"Churn\"].value_counts(normalize=True) * 100\n",
    "ax = sns.barplot(x=churn_percentages.index, y=churn_percentages.values, palette=\"plasma\")\n",
    "\n",
    "plt.xlabel(\"Churn (0 = No, 1 = Yes)\")\n",
    "plt.ylabel(\"Percentage (%)\")\n",
    "plt.title(\"Churn Distribution (Scaled)\")\n",
    "plt.ylim(0, 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This bar chart shows that our data is split 80/20 which is very imbalanced. This is very reasonable as it simply implies that most customers do not leave. But for our model to be able to predict the minority class, we need to balance the data. I will use `SMOTE` to oversample the minority class (1s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Handling the imbalance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=rs)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Before upsampling:\")\n",
    "print('count of Churn = 0: {}'.format(sum(y_train==0)))\n",
    "print('count of Churn = 1: {}'.format(sum(y_train==1)))\n",
    "print(f\"Training set's shape: {X_train.shape}\\n\")\n",
    "\n",
    "print('After upsampling')\n",
    "print('count of Churn = 0: {}'.format(sum(y_train_resampled==0)))\n",
    "print('count of Churn = 1: {}'.format(sum(y_train_resampled==1)))\n",
    "print(f\"Training set's shape: {X_train_resampled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Scaling the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_resampled)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Models\n",
    "\n",
    "This section will first focus on dismissing the linear approach. The main reason is:\n",
    "\n",
    "- A linear model is based on the assumption that the relationship between the input features and the \"Churn\" is linear. This is not the case.\n",
    "\n",
    "- The nature of a linear model's output is continuous, while the target variable here is binary (not churn / churn).\n",
    "\n",
    "Also note, that quadratic, cubic, etc. regressions, are still linear models, as the coefficientsassociated with the features are still linear, with just different powers. In other words, a linear regression is a polynomial regression of degree 1.\n",
    "\n",
    "### **Linear Regression**\n",
    "\n",
    "$$\n",
    "y = \\beta X + \\epsilon\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Performing Linear Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_linear = LinearRegression()\n",
    "model_linear.fit(X_train_scaled, y_train_resampled)\n",
    "y_pred_linear = model_linear.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Visualizing the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(range(len(y_test)), y_test, color='tab:blue', label='True', alpha=0.5)\n",
    "plt.scatter(range(len(y_pred_linear)), y_pred_linear, color='tab:red', label='Predicted', alpha=0.5)\n",
    "plt.title(\"Linear Regression: True vs Predicted Churn\")\n",
    "plt.xlabel(\"Sample Index\")\n",
    "plt.ylabel(\"Churn (0 or 1)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Evaluating Error**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_linear = mean_squared_error(y_test, y_pred_linear)\n",
    "r2_linear = r2_score(y_test, y_pred_linear)\n",
    "\n",
    "print(f\"Error Metrics: \\n\\nMSE: {mse_linear:.4f} \\nR^2: {r2_linear:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in the visualization of the predicted points, the predictions are continuous, which is not suitable for a binary classification problem. Moreover, a $R^2$ score of -0.02 indicates that the model does not only poorly fit the data, but also performs worse than a horizontal line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Polynomial Regression**\n",
    "\n",
    "$$\n",
    "y = \\beta_0 + \\beta_1 X + \\beta_2 X^2 + \\ldots + \\beta_n X^n+ \\epsilon\n",
    "$$\n",
    "\n",
    "As mentioned earlier, polynomial regression is still a linear model, as the coefficients associated with the features are still linear, with just different powers. The value of $n$ is the `degree` of the polynomial in our `PolynomialFeatures` function.\n",
    "\n",
    "1. **Calculating $X^2$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly2 = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_train_poly2 = poly2.fit_transform(X_train_scaled)\n",
    "X_test_poly2 = poly2.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Calculating $X^3$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly3 = PolynomialFeatures(degree=3, include_bias=False)\n",
    "X_train_poly3 = poly3.fit_transform(X_train_scaled)\n",
    "X_test_poly3 = poly3.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Performing Quadratic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_quadratic = LinearRegression()\n",
    "model_quadratic.fit(X_train_poly2, y_train_resampled)\n",
    "y_pred_quadratic = model_quadratic.predict(X_test_poly2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Performing Cubic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cubic = LinearRegression()\n",
    "model_cubic.fit(X_train_poly3, y_train_resampled)\n",
    "y_pred_cubic = model_cubic.predict(X_test_poly3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. **Visualizing the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 6))\n",
    "\n",
    "ax1.scatter(range(len(y_test)), y_test, color='tab:blue', label='True', alpha=0.5)\n",
    "ax1.scatter(range(len(y_pred_quadratic)), y_pred_quadratic, color='tab:red', label='Predicted', alpha=0.5)\n",
    "ax1.set_title(\"Quadratic Regression: True vs Predicted Churn\")\n",
    "ax1.set_xlabel(\"Sample Index\")\n",
    "ax1.set_ylabel(\"Churn (0 or 1)\")\n",
    "ax1.legend()\n",
    "\n",
    "ax2.scatter(range(len(y_test)), y_test, color='tab:blue', label='True', alpha=0.5)\n",
    "ax2.scatter(range(len(y_pred_cubic)), y_pred_cubic, color='tab:red', label='Predicted', alpha=0.5)\n",
    "ax2.set_title(\"Cubic Regression: True vs Predicted Churn\")\n",
    "ax2.set_xlabel(\"Sample Index\")\n",
    "ax2.set_ylabel(\"Churn (0 or 1)\")\n",
    "ax2.set_ylim(-0.75, 1.45)\n",
    "ax2.legend()\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_quadratic = mean_squared_error(y_test, y_pred_quadratic)\n",
    "r2_quadratic = r2_score(y_test, y_pred_quadratic)\n",
    "\n",
    "mse_cubic = mean_squared_error(y_test, y_pred_cubic)\n",
    "r2_cubic = r2_score(y_test, y_pred_cubic)\n",
    "\n",
    "print(f\"Error Metrics of Quadratic Model: \\n\\nMSE: {mse_quadratic:.4f} \\nR^2: {r2_quadratic:.4f}\\n\\n\")\n",
    "print(f\"Error Metrics of Cubic Model: \\n\\nMSE: {mse_cubic:.4f} \\nR^2: {r2_cubic:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets evaluate the visualizations of the quadratic and cubic regressions. At first glance it may seem that as we increase the degree of the polynomial, the model fits the data better. However, this is not the case. The model is overfitting the data, which is evident by the fact that the model is trying to fit every single point in the dataset. Moreover, the $R^2$ score of $-1.15 \\times 10^21$ indicates that the model is performing extremely poorly, learning from all the noise in the data, without having enough complexity to generalize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Logistic Regression**\n",
    "\n",
    "The first complex model we'll analyze is logistic regression, which tries to calculate the probability of some binary outcome:\n",
    "\n",
    "$$\n",
    "P(y=1) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1 X_1 + \\ldots + \\beta_n X_n)}}\n",
    "$$\n",
    "\n",
    "This model estimates $\\beta$ through maximum likelihood estimation by fitting a sigmoid function to the data. As shown in the equation, we can have $\\beta_n$ added to the model for regularization, which will help prevent overfitting.\n",
    "\n",
    "1. **Performing Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_logistic = LogisticRegression(random_state=rs, max_iter=1000)\n",
    "model_logistic.fit(X_train_scaled, y_train_resampled)\n",
    "\n",
    "y_pred_logistic = model_logistic.predict(X_test_scaled)\n",
    "y_pred_proba = model_logistic.predict_proba(X_test_scaled)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Visualizing the model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see how a real binary classification model looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(range(len(y_test)), y_test, color='tab:blue', label='True', alpha=0.5)\n",
    "plt.scatter(range(len(y_pred_logistic)), y_pred_logistic, color='tab:red', label='Predicted', alpha=0.5)\n",
    "plt.title(\"Logistic Regression: True vs Predicted Churn\")\n",
    "plt.xlabel(\"Sample Index\")\n",
    "plt.ylabel(\"Churn (0 or 1)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_logistic = confusion_matrix(y_test, y_pred_logistic)\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "sns.heatmap(cm_logistic, annot=True, fmt='d', cmap='Greys', cbar=False)\n",
    "plt.title('Logistic Regression')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Evaluating Error**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_logistic = mean_squared_error(y_test, y_pred_logistic)\n",
    "r2_logistic = r2_score(y_test, y_pred_logistic)\n",
    "accuracy_logistic = accuracy_score(y_test, y_pred_logistic)\n",
    "precision_logistic = precision_score(y_test, y_pred_logistic)\n",
    "recall_logistic = recall_score(y_test, y_pred_logistic)\n",
    "f1_logistic = f1_score(y_test, y_pred_logistic)\n",
    "\n",
    "print(f\"Error Metrics: \\n\\nMSE: {mse_logistic:.4}\\nR^2: {r2_logistic:.4f}\\n\\nAccuracy: {accuracy_logistic:.4f}\\nPrecision: {precision_logistic:.4f}\\nRecall: {recall_logistic:.4f}\\nF1: {f1_logistic:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in the confusion matrix, the model is performing decently on predicting the majority class, however, as the $R^2$ score suggests, the model is not performing well on the majority class, with an overall classification score of about 60%, indicated by the F1 score.\n",
    "\n",
    "**We can do better!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors (kNN) Models\n",
    "\n",
    "The next model we'll analyze is the k-Nearest Neighbors (kNN) model. This model is based on the assumption that similar data points are close to each other in the feature space. The model calculates the distance between the data points and classifies the data point based on the majority class of the k-nearest neighbors.\n",
    "\n",
    "I'll use three different distance metrics: Euclidean, Manhattan, and Hamming. My hypothesis is that each will perform better than the other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Euclidean Distance**\n",
    "\n",
    "$$\n",
    "d(x,y) = \\sqrt{\\sum_{i=1}^{n} (y_i - x_i)^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Performing Euclidean KNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_euc_knn = KNeighborsClassifier(n_neighbors=5, metric='euclidean')\n",
    "model_euc_knn.fit(X_train_scaled, y_train_resampled)\n",
    "y_pred_euc_knn = model_euc_knn.predict(X_test_scaled)\n",
    "y_pred_euc_knn_proba = model_euc_knn.predict_proba(X_test_scaled)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_euc_knn = confusion_matrix(y_test, y_pred_euc_knn)\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "sns.heatmap(cm_euc_knn, annot=True, fmt='d', cmap='Greys', cbar=False)\n",
    "plt.title('kNN (Euclidean)')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Evaluating Error**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_euc_knn = mean_squared_error(y_test, y_pred_euc_knn)\n",
    "r2_euc_knn = r2_score(y_test, y_pred_euc_knn)\n",
    "accuracy_euc_knn = accuracy_score(y_test, y_pred_euc_knn)\n",
    "precision_euc_knn = precision_score(y_test, y_pred_euc_knn)\n",
    "recall_euc_knn = recall_score(y_test, y_pred_euc_knn)\n",
    "f1_euc_knn = f1_score(y_test, y_pred_euc_knn)\n",
    "\n",
    "print(f\"Error Metrics: \\n\\nMSE: {mse_euc_knn:.4}\\nR^2: {r2_euc_knn:.4f}\\n\\nAccuracy: {accuracy_euc_knn:.4f}\\nPrecision: {precision_euc_knn:.4f}\\nRecall: {recall_euc_knn:.4f}\\nF1: {f1_euc_knn:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the confusion matrix, the model is performing better than the logistic regression model, with a higher F1 score. However, the model is still not performing well on the minority class, with an overall classification score of about 74%.\n",
    "\n",
    "One reason for this underperformance is that euclidean distance is assumes that all features are continuous, which is not the case in our dataset.\n",
    "\n",
    "Next, we'll try the Manhattan distance, which also assumes that all features are continuous, but for ones that don't fit on a straight line. It is also more robust to outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Manhattan Distance**\n",
    "\n",
    "$$\n",
    "d(x,y) = \\sum_{i=1}^{m} |x_i - y_i|\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Performing Manhattan KNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_man_knn = KNeighborsClassifier(n_neighbors=5, metric='manhattan')\n",
    "model_man_knn.fit(X_train_scaled, y_train_resampled)\n",
    "y_pred_man_knn = model_man_knn.predict(X_test_scaled)\n",
    "y_pred_man_knn_proba = model_man_knn.predict_proba(X_test_scaled)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_man_knn = confusion_matrix(y_test, y_pred_man_knn)\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "sns.heatmap(cm_man_knn, annot=True, fmt='d', cmap='Greys', cbar=False)\n",
    "plt.title('kNN (Manhattan)')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Evaluating Error**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_man_knn = mean_squared_error(y_test, y_pred_man_knn)\n",
    "r2_man_knn = r2_score(y_test, y_pred_man_knn)\n",
    "accuracy_man_knn = accuracy_score(y_test, y_pred_man_knn)\n",
    "precision_man_knn = precision_score(y_test, y_pred_man_knn)\n",
    "recall_man_knn = recall_score(y_test, y_pred_man_knn)\n",
    "f1_man_knn = f1_score(y_test, y_pred_man_knn)\n",
    "\n",
    "print(f\"Error Metrics: \\n\\nMSE: {mse_man_knn:.4}\\nR^2: {r2_man_knn:.4f}\\n\\nAccuracy: {accuracy_man_knn:.4f}\\nPrecision: {precision_man_knn:.4f}\\nRecall: {recall_man_knn:.4f}\\nF1: {f1_man_knn:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Much better!**\n",
    "\n",
    "The model is performing better than the Euclidean KNN model, with a higher F1 score of about 82%. The model is still not performing perfectly on the minority class but the $R^2$ is much better and MSE is much lower.\n",
    "\n",
    "But... we can make it a little better! (or can we?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Hamming Distance**\n",
    "\n",
    "Hamming distance does not have a equation formula. But I'll briefly explain it here.\n",
    "\n",
    "Let \"ABCDEFG\" and \"YBCNEXM\" be two strings of equal length 7. The Hamming distance between these two strings is the number of positions at which the corresponding characters are different. So: **A**BC**D**E**FG** and **Y**BC**N**E**XM** have 3 different characters, so the Hamming distance is 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Performing Hamming KNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ham_knn = KNeighborsClassifier(n_neighbors=5, metric='hamming')\n",
    "model_ham_knn.fit(X_train_scaled, y_train_resampled)\n",
    "y_pred_ham_knn = model_ham_knn.predict(X_test_scaled)\n",
    "y_pred_ham_knn_proba = model_ham_knn.predict_proba(X_test_scaled)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_ham_knn = confusion_matrix(y_test, y_pred_ham_knn)\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "sns.heatmap(cm_ham_knn, annot=True, fmt='d', cmap='Greys', cbar=False)\n",
    "plt.title('kNN (Hamming)')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Evaluating Error**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_ham_knn = mean_squared_error(y_test, y_pred_ham_knn)\n",
    "r2_ham_knn = r2_score(y_test, y_pred_ham_knn)\n",
    "accuracy_ham_knn = accuracy_score(y_test, y_pred_ham_knn)\n",
    "precision_ham_knn = precision_score(y_test, y_pred_ham_knn)\n",
    "recall_ham_knn = recall_score(y_test, y_pred_ham_knn)\n",
    "f1_ham_knn = f1_score(y_test, y_pred_ham_knn)\n",
    "\n",
    "print(f\"Error Metrics: \\n\\nMSE: {mse_ham_knn:.4}\\nR^2: {r2_ham_knn:.4f}\\n\\nAccuracy: {accuracy_ham_knn:.4f}\\nPrecision: {precision_ham_knn:.4f}\\nRecall: {recall_ham_knn:.4f}\\nF1: {f1_ham_knn:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting...\n",
    "\n",
    "So of course this is not a good model for this dataset. The Hamming distance is not suitable for this dataset, as it assumes that all features are categorical, which is not the case in our dataset. It views each feature individually, and does not take into account the relationship between them. This also means if one of them have a missmatch, it will infleunce the model greatly.\n",
    "\n",
    "So the winner here is the Manhattan distance kNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine (SVM) Model\n",
    "\n",
    "### **Linear SVM**\n",
    "\n",
    "The linear SVM tries to find a linear hyperplane that separate the data points into two classes, by checking for this condition to hold at all times:\n",
    "\n",
    "$$\n",
    "y_i(w^T X_i + b) \\geq 1\n",
    "$$\n",
    "\n",
    "\n",
    "1. **Performing SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_svc = SVC(kernel='linear', random_state=rs, probability=True)\n",
    "model_svc.fit(X_train_scaled, y_train_resampled)\n",
    "y_pred_svc = model_svc.predict(X_test_scaled)\n",
    "y_pred_svc_proba = model_svc.predict_proba(X_test_scaled)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_svc = confusion_matrix(y_test, y_pred_svc)\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "sns.heatmap(cm_svc, annot=True, fmt='d', cmap='Greys', cbar=False)\n",
    "plt.title('SVM (Linear)')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Evaluating Error**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_svc = mean_squared_error(y_test, y_pred_svc)\n",
    "r2_svc = r2_score(y_test, y_pred_svc)\n",
    "accuracy_svc = accuracy_score(y_test, y_pred_svc)\n",
    "precision_svc = precision_score(y_test, y_pred_svc)\n",
    "recall_svc = recall_score(y_test, y_pred_svc)\n",
    "f1_svc = f1_score(y_test, y_pred_svc)\n",
    "\n",
    "print(f\"Error Metrics: \\n\\nMSE: {mse_svc:.4}\\nR^2: {r2_svc:.4f}\\n\\nAccuracy: {accuracy_svc:.4f}\\nPrecision: {precision_svc:.4f}\\nRecall: {recall_svc:.4f}\\nF1: {f1_svc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The negative $R^2$ alone indicates that the model is not performing well. Although the MSE is not terrible, probably due to the fact that its prediciting the majority class well, the F1 score is still not good. \n",
    "\n",
    "This means our data is too complex for a linear hyperplane, and a more complex algorithm is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Non-Linear SVM**\n",
    "\n",
    "$$\n",
    "K(x,x′)=exp(−γ∥x−x′∥ 2)\n",
    "$$\n",
    "\n",
    "The non linear SVM uses the kernel trick to transform the data into a higher dimensional space, where it can find a hyperplane that separates the data points into two classes. The higher the value of $\\gamma$, the more complex the model will be and the less smooth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-linear kernel\n",
    "model_rbf_svc = SVC(kernel='rbf', random_state=rs, probability=True)\n",
    "model_rbf_svc.fit(X_train_scaled, y_train_resampled)\n",
    "y_pred_rbf_svc = model_rbf_svc.predict(X_test_scaled)\n",
    "y_pred_rbf_svc_proba = model_rbf_svc.predict_proba(X_test_scaled)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_rbf_svc = confusion_matrix(y_test, y_pred_rbf_svc)\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "sns.heatmap(cm_rbf_svc, annot=True, fmt='d', cmap='Greys', cbar=False)\n",
    "plt.title('SVM (RBF)')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_rbf_svc = mean_squared_error(y_test, y_pred_rbf_svc)\n",
    "r2_rbf_svc = r2_score(y_test, y_pred_rbf_svc)\n",
    "accuracy_rbf_svc = accuracy_score(y_test, y_pred_rbf_svc)\n",
    "precision_rbf_svc = precision_score(y_test, y_pred_rbf_svc)\n",
    "recall_rbf_svc = recall_score(y_test, y_pred_rbf_svc)\n",
    "f1_rbf_svc = f1_score(y_test, y_pred_rbf_svc)\n",
    "\n",
    "print(f\"Error Metrics: \\n\\nMSE: {mse_rbf_svc:.4}\\nR^2: {r2_rbf_svc:.4f}\\n\\nAccuracy: {accuracy_rbf_svc:.4f}\\nPrecision: {precision_rbf_svc:.4f}\\nRecall: {recall_rbf_svc:.4f}\\nF1: {f1_rbf_svc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Good!**\n",
    "\n",
    "This model is fitting the data pretty decently with $R^2 = 0.5$ and an F1 score of 81%. This is a good model for this dataset overall.\n",
    "\n",
    "It is important to mention that a non-linear SVM means a lot of computational power, as it needs to calculate the kernel for every data point, which can be very time consuming, and not the best model either for our data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
